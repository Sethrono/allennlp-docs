

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>allennlp.data.token_indexers &mdash; AllenNLP 0.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="AllenNLP 0.0 documentation" href="../index.html"/>
        <link rel="up" title="allennlp.data" href="allennlp.data.html"/>
        <link rel="next" title="allennlp.data.tokenizers" href="allennlp.data.tokenizers.html"/>
        <link rel="prev" title="allennlp.data.iterators" href="allennlp.data.iterators.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/allennlp-logo-dark.png" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                0.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="allennlp.commands.html">allennlp.commands</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.subcommand.html">allennlp.commands.subcommand</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.evaluate.html">allennlp.commands.evaluate</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.predict.html">allennlp.commands.predict</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.serve.html">allennlp.commands.serve</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.train.html">allennlp.commands.train</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.common.html">allennlp.common</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.checks.html">allennlp.common.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.file_utils.html">allennlp.common.file_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.params.html">allennlp.common.params</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.registrable.html">allennlp.common.registrable</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.squad_eval.html">allennlp.common.squad_eval</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.tee_logger.html">allennlp.common.tee_logger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.testing.html">allennlp.common.testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.util.html">allennlp.common.util</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="allennlp.data.html">allennlp.data</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset.html">allennlp.data.dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset_readers.html">allennlp.data.dataset_readers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.dataset_reader.html">allennlp.data.dataset_readers.dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.conll2003.html">allennlp.data.dataset_readers.conll2003</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.language_modeling.html">allennlp.data.dataset_readers.language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.reading_comprehension.html">allennlp.data.dataset_readers.reading_comprehension</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.coreference_resolution.html">allennlp.data.dataset_readers.coreference_resolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_role_labeling.html">allennlp.data.dataset_readers.semantic_role_labeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.seq2seq.html">allennlp.data.dataset_readers.seq2seq</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.sequence_tagging.html">allennlp.data.dataset_readers.sequence_tagging</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.snli.html">allennlp.data.dataset_readers.snli</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.fields.html">allennlp.data.fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.instance.html">allennlp.data.instance</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.iterators.html">allennlp.data.iterators</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">allennlp.data.token_indexers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.tokenizers.html">allennlp.data.tokenizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.vocabulary.html">allennlp.data.vocabulary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.models.html">allennlp.models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.model.html">allennlp.models.model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.archival.html">allennlp.models.archival</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.crf_tagger.html">allennlp.models.crf_tagger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.decomposable_attention.html">allennlp.models.decomposable_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.encoder_decoders.html">allennlp.models.encoder_decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.reading_comprehension.html">allennlp.models.reading_comprehension</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.coreference_resolution.html">allennlp.models.coreference_resolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.semantic_role_labeler.html">allennlp.models.semantic_role_labeler</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.simple_tagger.html">allennlp.models.simple_tagger</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.modules.html">allennlp.modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.attention.html">allennlp.modules.attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.augmented_lstm.html">allennlp.modules.augmented_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.lstm_cell_with_projection.html">allennlp.modules.lstm_cell_with_projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_elmo_lstm.html">allennlp.modules.stacked_elmo_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.conditional_random_field.html">allennlp.modules.conditional_random_field</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.feedforward.html">allennlp.modules.feedforward</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.highway.html">allennlp.modules.highway</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.matrix_attention.html">allennlp.modules.matrix_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2seq_encoders.html">allennlp.modules.seq2seq_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2vec_encoders.html">allennlp.modules.seq2vec_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.similarity_functions.html">allennlp.modules.similarity_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_alternating_lstm.html">allennlp.modules.stacked_alternating_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.text_field_embedders.html">allennlp.modules.text_field_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.time_distributed.html">allennlp.modules.time_distributed</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.token_embedders.html">allennlp.modules.token_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.scalar_mix.html">allennlp.modules.scalar_mix</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.nn.html">allennlp.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.activations.html">allennlp.nn.activations</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.initializers.html">allennlp.nn.initializers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.regularizers.html">allennlp.nn.regularizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.util.html">allennlp.nn.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.service.html">allennlp.service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.db.html">allennlp.service.db</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.permalinks.html">allennlp.service.permalinks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.predictors.html">allennlp.service.predictors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.server_sanic.html">allennlp.service.server_sanic</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.training.html">allennlp.training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.learning_rate_schedulers.html">allennlp.training.learning_rate_schedulers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.metrics.html">allennlp.training.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.optimizers.html">allennlp.training.optimizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer.html">allennlp.training.trainer</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">AllenNLP</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="allennlp.data.html">allennlp.data</a> &raquo;</li>
        
      <li>allennlp.data.token_indexers</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api/allennlp.data.token_indexers.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-allennlp.data.token_indexers">
<span id="allennlp-data-token-indexers"></span><h1>allennlp.data.token_indexers<a class="headerlink" href="#module-allennlp.data.token_indexers" title="Permalink to this headline">¶</a></h1>
<p>A <code class="docutils literal"><span class="pre">TokenIndexer</span></code> determines how string tokens get represented as arrays of indices in a model.</p>
<ul class="simple">
<li><a class="reference internal" href="#token-indexer"><span class="std std-ref">TokenIndexer</span></a></li>
<li><a class="reference internal" href="#dep-label-indexer"><span class="std std-ref">DepLabelIndexer</span></a></li>
<li><a class="reference internal" href="#ner-tag-indexer"><span class="std std-ref">NerTagIndexer</span></a></li>
<li><a class="reference internal" href="#pos-tag-indexer"><span class="std std-ref">PosTagIndexer</span></a></li>
<li><a class="reference internal" href="#single-id-token-indexer"><span class="std std-ref">SingleIdTokenIndexer</span></a></li>
<li><a class="reference internal" href="#token-characters-indexer"><span class="std std-ref">TokenCharactersIndexer</span></a></li>
<li><a class="reference internal" href="#elmo-indexer"><span class="std std-ref">ELMoTokenCharactersIndexer</span></a></li>
</ul>
<span class="target" id="module-allennlp.data.token_indexers.token_indexer"><span id="token-indexer"></span></span><dl class="class">
<dt id="allennlp.data.token_indexers.token_indexer.TokenIndexer">
<em class="property">class </em><code class="descclassname">allennlp.data.token_indexers.token_indexer.</code><code class="descname">TokenIndexer</code><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/token_indexer.py#L9-L92"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">typing.Generic</span></code>, <a class="reference internal" href="allennlp.common.registrable.html#allennlp.common.registrable.Registrable" title="allennlp.common.registrable.Registrable"><code class="xref py py-class docutils literal"><span class="pre">allennlp.common.registrable.Registrable</span></code></a></p>
<p>A <code class="docutils literal"><span class="pre">TokenIndexer</span></code> determines how string tokens get represented as arrays of indices in a model.
This class both converts strings into numerical values, with the help of a
<a class="reference internal" href="allennlp.data.vocabulary.html#allennlp.data.vocabulary.Vocabulary" title="allennlp.data.vocabulary.Vocabulary"><code class="xref py py-class docutils literal"><span class="pre">Vocabulary</span></code></a>,
and it produces actual arrays.</p>
<p>Tokens can be represented as single IDs (e.g., the word &#8220;cat&#8221; gets represented by the number
34), or as lists of character IDs (e.g., &#8220;cat&#8221; gets represented by the numbers [23, 10, 18]),
or in some other way that you can come up with (e.g., if you have some structured input you
want to represent in a special way in your data arrays, you can do that here).</p>
<dl class="method">
<dt id="allennlp.data.token_indexers.token_indexer.TokenIndexer.count_vocab_items">
<code class="descname">count_vocab_items</code><span class="sig-paren">(</span><em>token: allennlp.data.tokenizers.token.Token, counter: typing.Dict[str, typing.Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/token_indexer.py#L23-L32"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>The <code class="xref py py-class docutils literal"><span class="pre">Vocabulary</span></code> needs to assign indices to whatever strings we see in the training
data (possibly doing some frequency filtering and using an OOV token).  This method takes
a token and a dictionary of counts and increments counts for whatever vocabulary items are
present in the token.  If this is a single token ID representation, the vocabulary item is
likely the token itself.  If this is a token characters representation, the vocabulary
items are all of the characters in the token.</p>
</dd></dl>

<dl class="attribute">
<dt id="allennlp.data.token_indexers.token_indexer.TokenIndexer.default_implementation">
<code class="descname">default_implementation</code><em class="property"> = 'single_id'</em><a class="headerlink" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer.default_implementation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="allennlp.data.token_indexers.token_indexer.TokenIndexer.dict_from_params">
<em class="property">classmethod </em><code class="descname">dict_from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; typing.Dict[str, allennlp.data.token_indexers.token_indexer.TokenIndexer]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/token_indexer.py#L75-L92"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer.dict_from_params" title="Permalink to this definition">¶</a></dt>
<dd><p>We typically use <code class="docutils literal"><span class="pre">TokenIndexers</span></code> in a dictionary, with each <code class="docutils literal"><span class="pre">TokenIndexer</span></code> getting a
name.  The specification for this in a <code class="docutils literal"><span class="pre">Params</span></code> object is typically <code class="docutils literal"><span class="pre">{&quot;name&quot;</span> <span class="pre">-&gt;</span>
<span class="pre">{indexer_params}}</span></code>.  This method reads that whole set of parameters and returns a
dictionary suitable for use in a <code class="docutils literal"><span class="pre">TextField</span></code>.</p>
<p>Because default values for token indexers are typically handled in the calling class to
this and are based on checking for <code class="docutils literal"><span class="pre">None</span></code>, if there were no parameters specifying any
token indexers in the given <code class="docutils literal"><span class="pre">params</span></code>, we return <code class="docutils literal"><span class="pre">None</span></code> instead of an empty dictionary.</p>
</dd></dl>

<dl class="classmethod">
<dt id="allennlp.data.token_indexers.token_indexer.TokenIndexer.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.token_indexers.token_indexer.TokenIndexer<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/token_indexer.py#L70-L73"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.token_indexer.TokenIndexer.get_padding_lengths">
<code class="descname">get_padding_lengths</code><span class="sig-paren">(</span><em>token: TokenType</em><span class="sig-paren">)</span> &#x2192; typing.Dict[str, int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/token_indexer.py#L49-L55"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>This method returns a padding dictionary for the given token.  For single ID tokens, e.g.,
this dictionary will be empty, but for a token characters representation, this will return
the number of characters in the token.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.token_indexer.TokenIndexer.get_padding_token">
<code class="descname">get_padding_token</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; TokenType<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/token_indexer.py#L42-L47"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer.get_padding_token" title="Permalink to this definition">¶</a></dt>
<dd><p>When we need to add padding tokens, what should they look like?  This method returns a
&#8220;blank&#8221; token of whatever type is returned by <a class="reference internal" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer.token_to_indices" title="allennlp.data.token_indexers.token_indexer.TokenIndexer.token_to_indices"><code class="xref py py-func docutils literal"><span class="pre">token_to_indices()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.token_indexer.TokenIndexer.pad_token_sequence">
<code class="descname">pad_token_sequence</code><span class="sig-paren">(</span><em>tokens: typing.List[TokenType], desired_num_tokens: int, padding_lengths: typing.Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; typing.List[TokenType]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/token_indexer.py#L57-L68"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer.pad_token_sequence" title="Permalink to this definition">¶</a></dt>
<dd><p>This method pads a list of tokens to <code class="docutils literal"><span class="pre">desired_num_tokens</span></code>, including any necessary
internal padding using whatever lengths are relevant in <code class="docutils literal"><span class="pre">padding_lengths</span></code>, returning a
padded copy of the input list.  If each token is a single ID, this just adds 0 to the
sequence (or truncates the sequence, if necessary).  If each token is, e.g., a list of
characters, this method will pad both the characters and the number of tokens.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.token_indexer.TokenIndexer.token_to_indices">
<code class="descname">token_to_indices</code><span class="sig-paren">(</span><em>token: allennlp.data.tokenizers.token.Token</em>, <em>vocabulary: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span> &#x2192; TokenType<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/token_indexer.py#L34-L40"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer.token_to_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes a string token and converts it into indices in some fashion.  This could be returning
an ID for the token from the vocabulary, or it could be splitting the token into characters
and return a list of IDs for each character from the vocabulary, or something else.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.token_indexers.dep_label_indexer"><span id="dep-label-indexer"></span></span><dl class="class">
<dt id="allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer">
<em class="property">class </em><code class="descclassname">allennlp.data.token_indexers.dep_label_indexer.</code><code class="descname">DepLabelIndexer</code><span class="sig-paren">(</span><em>namespace: str = 'dep_labels'</em><span class="sig-paren">)</span> &#x2192; None<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/dep_label_indexer.py#L16-L65"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer" title="allennlp.data.token_indexers.token_indexer.TokenIndexer"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.token_indexers.token_indexer.TokenIndexer</span></code></a></p>
<p>This <code class="xref py py-class docutils literal"><span class="pre">TokenIndexer</span></code> represents tokens by their syntactic dependency label, as determined
by the <code class="docutils literal"><span class="pre">dep_</span></code> field on <code class="docutils literal"><span class="pre">Token</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>namespace</strong> : <code class="docutils literal"><span class="pre">str</span></code>, optional (default=``dep_labels``)</p>
<blockquote class="last">
<div><p>We will use this namespace in the <code class="xref py py-class docutils literal"><span class="pre">Vocabulary</span></code> to map strings to indices.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer.count_vocab_items">
<code class="descname">count_vocab_items</code><span class="sig-paren">(</span><em>token: allennlp.data.tokenizers.token.Token, counter: typing.Dict[str, typing.Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/dep_label_indexer.py#L31-L39"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>The <code class="xref py py-class docutils literal"><span class="pre">Vocabulary</span></code> needs to assign indices to whatever strings we see in the training
data (possibly doing some frequency filtering and using an OOV token).  This method takes
a token and a dictionary of counts and increments counts for whatever vocabulary items are
present in the token.  If this is a single token ID representation, the vocabulary item is
likely the token itself.  If this is a token characters representation, the vocabulary
items are all of the characters in the token.</p>
</dd></dl>

<dl class="classmethod">
<dt id="allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/dep_label_indexer.py#L61-L65"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer.get_padding_lengths">
<code class="descname">get_padding_lengths</code><span class="sig-paren">(</span><em>token: int</em><span class="sig-paren">)</span> &#x2192; typing.Dict[str, int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/dep_label_indexer.py#L50-L52"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>This method returns a padding dictionary for the given token.  For single ID tokens, e.g.,
this dictionary will be empty, but for a token characters representation, this will return
the number of characters in the token.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer.get_padding_token">
<code class="descname">get_padding_token</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/dep_label_indexer.py#L46-L48"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer.get_padding_token" title="Permalink to this definition">¶</a></dt>
<dd><p>When we need to add padding tokens, what should they look like?  This method returns a
&#8220;blank&#8221; token of whatever type is returned by <a class="reference internal" href="#allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer.token_to_indices" title="allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer.token_to_indices"><code class="xref py py-func docutils literal"><span class="pre">token_to_indices()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer.pad_token_sequence">
<code class="descname">pad_token_sequence</code><span class="sig-paren">(</span><em>tokens: typing.List[int], desired_num_tokens: int, padding_lengths: typing.Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; typing.List[int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/dep_label_indexer.py#L54-L59"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer.pad_token_sequence" title="Permalink to this definition">¶</a></dt>
<dd><p>This method pads a list of tokens to <code class="docutils literal"><span class="pre">desired_num_tokens</span></code>, including any necessary
internal padding using whatever lengths are relevant in <code class="docutils literal"><span class="pre">padding_lengths</span></code>, returning a
padded copy of the input list.  If each token is a single ID, this just adds 0 to the
sequence (or truncates the sequence, if necessary).  If each token is, e.g., a list of
characters, this method will pad both the characters and the number of tokens.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer.token_to_indices">
<code class="descname">token_to_indices</code><span class="sig-paren">(</span><em>token: allennlp.data.tokenizers.token.Token</em>, <em>vocabulary: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/dep_label_indexer.py#L41-L44"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.dep_label_indexer.DepLabelIndexer.token_to_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes a string token and converts it into indices in some fashion.  This could be returning
an ID for the token from the vocabulary, or it could be splitting the token into characters
and return a list of IDs for each character from the vocabulary, or something else.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.token_indexers.ner_tag_indexer"><span id="ner-tag-indexer"></span></span><dl class="class">
<dt id="allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer">
<em class="property">class </em><code class="descclassname">allennlp.data.token_indexers.ner_tag_indexer.</code><code class="descname">NerTagIndexer</code><span class="sig-paren">(</span><em>namespace: str = 'ner_tags'</em><span class="sig-paren">)</span> &#x2192; None<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/ner_tag_indexer.py#L16-L63"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer" title="allennlp.data.token_indexers.token_indexer.TokenIndexer"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.token_indexers.token_indexer.TokenIndexer</span></code></a></p>
<p>This <code class="xref py py-class docutils literal"><span class="pre">TokenIndexer</span></code> represents tokens by their entity type (i.e., their NER tag), as
determined by the <code class="docutils literal"><span class="pre">ent_type_</span></code> field on <code class="docutils literal"><span class="pre">Token</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>namespace</strong> : <code class="docutils literal"><span class="pre">str</span></code>, optional (default=``ner_tags``)</p>
<blockquote class="last">
<div><p>We will use this namespace in the <code class="xref py py-class docutils literal"><span class="pre">Vocabulary</span></code> to map strings to indices.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer.count_vocab_items">
<code class="descname">count_vocab_items</code><span class="sig-paren">(</span><em>token: allennlp.data.tokenizers.token.Token, counter: typing.Dict[str, typing.Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/ner_tag_indexer.py#L30-L35"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>The <code class="xref py py-class docutils literal"><span class="pre">Vocabulary</span></code> needs to assign indices to whatever strings we see in the training
data (possibly doing some frequency filtering and using an OOV token).  This method takes
a token and a dictionary of counts and increments counts for whatever vocabulary items are
present in the token.  If this is a single token ID representation, the vocabulary item is
likely the token itself.  If this is a token characters representation, the vocabulary
items are all of the characters in the token.</p>
</dd></dl>

<dl class="classmethod">
<dt id="allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/ner_tag_indexer.py#L59-L63"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer.get_padding_lengths">
<code class="descname">get_padding_lengths</code><span class="sig-paren">(</span><em>token: int</em><span class="sig-paren">)</span> &#x2192; typing.Dict[str, int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/ner_tag_indexer.py#L48-L50"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>This method returns a padding dictionary for the given token.  For single ID tokens, e.g.,
this dictionary will be empty, but for a token characters representation, this will return
the number of characters in the token.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer.get_padding_token">
<code class="descname">get_padding_token</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/ner_tag_indexer.py#L44-L46"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer.get_padding_token" title="Permalink to this definition">¶</a></dt>
<dd><p>When we need to add padding tokens, what should they look like?  This method returns a
&#8220;blank&#8221; token of whatever type is returned by <a class="reference internal" href="#allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer.token_to_indices" title="allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer.token_to_indices"><code class="xref py py-func docutils literal"><span class="pre">token_to_indices()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer.pad_token_sequence">
<code class="descname">pad_token_sequence</code><span class="sig-paren">(</span><em>tokens: typing.List[int], desired_num_tokens: int, padding_lengths: typing.Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; typing.List[int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/ner_tag_indexer.py#L52-L57"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer.pad_token_sequence" title="Permalink to this definition">¶</a></dt>
<dd><p>This method pads a list of tokens to <code class="docutils literal"><span class="pre">desired_num_tokens</span></code>, including any necessary
internal padding using whatever lengths are relevant in <code class="docutils literal"><span class="pre">padding_lengths</span></code>, returning a
padded copy of the input list.  If each token is a single ID, this just adds 0 to the
sequence (or truncates the sequence, if necessary).  If each token is, e.g., a list of
characters, this method will pad both the characters and the number of tokens.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer.token_to_indices">
<code class="descname">token_to_indices</code><span class="sig-paren">(</span><em>token: allennlp.data.tokenizers.token.Token</em>, <em>vocabulary: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/ner_tag_indexer.py#L37-L42"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.ner_tag_indexer.NerTagIndexer.token_to_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes a string token and converts it into indices in some fashion.  This could be returning
an ID for the token from the vocabulary, or it could be splitting the token into characters
and return a list of IDs for each character from the vocabulary, or something else.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.token_indexers.pos_tag_indexer"><span id="pos-tag-indexer"></span></span><dl class="class">
<dt id="allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer">
<em class="property">class </em><code class="descclassname">allennlp.data.token_indexers.pos_tag_indexer.</code><code class="descname">PosTagIndexer</code><span class="sig-paren">(</span><em>namespace: str = 'pos_tags'</em>, <em>coarse_tags: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/pos_tag_indexer.py#L16-L78"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer" title="allennlp.data.token_indexers.token_indexer.TokenIndexer"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.token_indexers.token_indexer.TokenIndexer</span></code></a></p>
<p>This <code class="xref py py-class docutils literal"><span class="pre">TokenIndexer</span></code> represents tokens by their part of speech tag, as determined by
the <code class="docutils literal"><span class="pre">pos_</span></code> or <code class="docutils literal"><span class="pre">tag_</span></code> fields on <code class="docutils literal"><span class="pre">Token</span></code> (corresponding to spacy&#8217;s coarse-grained and
fine-grained POS tags, respectively).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>namespace</strong> : <code class="docutils literal"><span class="pre">str</span></code>, optional (default=``pos_tags``)</p>
<blockquote>
<div><p>We will use this namespace in the <code class="xref py py-class docutils literal"><span class="pre">Vocabulary</span></code> to map strings to indices.</p>
</div></blockquote>
<p><strong>coarse_tags</strong> : <code class="docutils literal"><span class="pre">bool</span></code>, optional (default=``False``)</p>
<blockquote class="last">
<div><p>If <code class="docutils literal"><span class="pre">True</span></code>, we will use coarse POS tags instead of the default fine-grained POS tags.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer.count_vocab_items">
<code class="descname">count_vocab_items</code><span class="sig-paren">(</span><em>token: allennlp.data.tokenizers.token.Token, counter: typing.Dict[str, typing.Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/pos_tag_indexer.py#L35-L46"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>The <code class="xref py py-class docutils literal"><span class="pre">Vocabulary</span></code> needs to assign indices to whatever strings we see in the training
data (possibly doing some frequency filtering and using an OOV token).  This method takes
a token and a dictionary of counts and increments counts for whatever vocabulary items are
present in the token.  If this is a single token ID representation, the vocabulary item is
likely the token itself.  If this is a token characters representation, the vocabulary
items are all of the characters in the token.</p>
</dd></dl>

<dl class="classmethod">
<dt id="allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/pos_tag_indexer.py#L73-L78"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer.get_padding_lengths">
<code class="descname">get_padding_lengths</code><span class="sig-paren">(</span><em>token: int</em><span class="sig-paren">)</span> &#x2192; typing.Dict[str, int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/pos_tag_indexer.py#L62-L64"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>This method returns a padding dictionary for the given token.  For single ID tokens, e.g.,
this dictionary will be empty, but for a token characters representation, this will return
the number of characters in the token.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer.get_padding_token">
<code class="descname">get_padding_token</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/pos_tag_indexer.py#L58-L60"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer.get_padding_token" title="Permalink to this definition">¶</a></dt>
<dd><p>When we need to add padding tokens, what should they look like?  This method returns a
&#8220;blank&#8221; token of whatever type is returned by <a class="reference internal" href="#allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer.token_to_indices" title="allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer.token_to_indices"><code class="xref py py-func docutils literal"><span class="pre">token_to_indices()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer.pad_token_sequence">
<code class="descname">pad_token_sequence</code><span class="sig-paren">(</span><em>tokens: typing.List[int], desired_num_tokens: int, padding_lengths: typing.Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; typing.List[int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/pos_tag_indexer.py#L66-L71"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer.pad_token_sequence" title="Permalink to this definition">¶</a></dt>
<dd><p>This method pads a list of tokens to <code class="docutils literal"><span class="pre">desired_num_tokens</span></code>, including any necessary
internal padding using whatever lengths are relevant in <code class="docutils literal"><span class="pre">padding_lengths</span></code>, returning a
padded copy of the input list.  If each token is a single ID, this just adds 0 to the
sequence (or truncates the sequence, if necessary).  If each token is, e.g., a list of
characters, this method will pad both the characters and the number of tokens.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer.token_to_indices">
<code class="descname">token_to_indices</code><span class="sig-paren">(</span><em>token: allennlp.data.tokenizers.token.Token</em>, <em>vocabulary: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/pos_tag_indexer.py#L48-L56"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.pos_tag_indexer.PosTagIndexer.token_to_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes a string token and converts it into indices in some fashion.  This could be returning
an ID for the token from the vocabulary, or it could be splitting the token into characters
and return a list of IDs for each character from the vocabulary, or something else.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.token_indexers.single_id_token_indexer"><span id="single-id-token-indexer"></span></span><dl class="class">
<dt id="allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer">
<em class="property">class </em><code class="descclassname">allennlp.data.token_indexers.single_id_token_indexer.</code><code class="descname">SingleIdTokenIndexer</code><span class="sig-paren">(</span><em>namespace: str = 'tokens'</em>, <em>lowercase_tokens: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/single_id_token_indexer.py#L13-L73"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer" title="allennlp.data.token_indexers.token_indexer.TokenIndexer"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.token_indexers.token_indexer.TokenIndexer</span></code></a></p>
<p>This <code class="xref py py-class docutils literal"><span class="pre">TokenIndexer</span></code> represents tokens as single integers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>namespace</strong> : <code class="docutils literal"><span class="pre">str</span></code>, optional (default=``tokens``)</p>
<blockquote>
<div><p>We will use this namespace in the <code class="xref py py-class docutils literal"><span class="pre">Vocabulary</span></code> to map strings to indices.</p>
</div></blockquote>
<p><strong>lowercase_tokens</strong> : <code class="docutils literal"><span class="pre">bool</span></code>, optional (default=``False``)</p>
<blockquote class="last">
<div><p>If <code class="docutils literal"><span class="pre">True</span></code>, we will call <code class="docutils literal"><span class="pre">token.lower()</span></code> before getting an index for the token from the
vocabulary.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.count_vocab_items">
<code class="descname">count_vocab_items</code><span class="sig-paren">(</span><em>token: allennlp.data.tokenizers.token.Token, counter: typing.Dict[str, typing.Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/single_id_token_indexer.py#L30-L38"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>The <code class="xref py py-class docutils literal"><span class="pre">Vocabulary</span></code> needs to assign indices to whatever strings we see in the training
data (possibly doing some frequency filtering and using an OOV token).  This method takes
a token and a dictionary of counts and increments counts for whatever vocabulary items are
present in the token.  If this is a single token ID representation, the vocabulary item is
likely the token itself.  If this is a token characters representation, the vocabulary
items are all of the characters in the token.</p>
</dd></dl>

<dl class="classmethod">
<dt id="allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/single_id_token_indexer.py#L68-L73"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.get_padding_lengths">
<code class="descname">get_padding_lengths</code><span class="sig-paren">(</span><em>token: int</em><span class="sig-paren">)</span> &#x2192; typing.Dict[str, int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/single_id_token_indexer.py#L57-L59"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>This method returns a padding dictionary for the given token.  For single ID tokens, e.g.,
this dictionary will be empty, but for a token characters representation, this will return
the number of characters in the token.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.get_padding_token">
<code class="descname">get_padding_token</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/single_id_token_indexer.py#L53-L55"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.get_padding_token" title="Permalink to this definition">¶</a></dt>
<dd><p>When we need to add padding tokens, what should they look like?  This method returns a
&#8220;blank&#8221; token of whatever type is returned by <a class="reference internal" href="#allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.token_to_indices" title="allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.token_to_indices"><code class="xref py py-func docutils literal"><span class="pre">token_to_indices()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.pad_token_sequence">
<code class="descname">pad_token_sequence</code><span class="sig-paren">(</span><em>tokens: typing.List[int], desired_num_tokens: int, padding_lengths: typing.Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; typing.List[int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/single_id_token_indexer.py#L61-L66"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.pad_token_sequence" title="Permalink to this definition">¶</a></dt>
<dd><p>This method pads a list of tokens to <code class="docutils literal"><span class="pre">desired_num_tokens</span></code>, including any necessary
internal padding using whatever lengths are relevant in <code class="docutils literal"><span class="pre">padding_lengths</span></code>, returning a
padded copy of the input list.  If each token is a single ID, this just adds 0 to the
sequence (or truncates the sequence, if necessary).  If each token is, e.g., a list of
characters, this method will pad both the characters and the number of tokens.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.token_to_indices">
<code class="descname">token_to_indices</code><span class="sig-paren">(</span><em>token: allennlp.data.tokenizers.token.Token</em>, <em>vocabulary: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span> &#x2192; int<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/single_id_token_indexer.py#L40-L51"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.single_id_token_indexer.SingleIdTokenIndexer.token_to_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes a string token and converts it into indices in some fashion.  This could be returning
an ID for the token from the vocabulary, or it could be splitting the token into characters
and return a list of IDs for each character from the vocabulary, or something else.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.token_indexers.token_characters_indexer"><span id="token-characters-indexer"></span></span><dl class="class">
<dt id="allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer">
<em class="property">class </em><code class="descclassname">allennlp.data.token_indexers.token_characters_indexer.</code><code class="descname">TokenCharactersIndexer</code><span class="sig-paren">(</span><em>namespace: str = 'token_characters'</em>, <em>character_tokenizer: allennlp.data.tokenizers.character_tokenizer.CharacterTokenizer = &lt;allennlp.data.tokenizers.character_tokenizer.CharacterTokenizer object&gt;</em><span class="sig-paren">)</span> &#x2192; None<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/token_characters_indexer.py#L16-L110"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer" title="allennlp.data.token_indexers.token_indexer.TokenIndexer"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.token_indexers.token_indexer.TokenIndexer</span></code></a></p>
<p>This <code class="xref py py-class docutils literal"><span class="pre">TokenIndexer</span></code> represents tokens as lists of character indices.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>namespace</strong> : <code class="docutils literal"><span class="pre">str</span></code>, optional (default=``token_characters``)</p>
<blockquote>
<div><p>We will use this namespace in the <code class="xref py py-class docutils literal"><span class="pre">Vocabulary</span></code> to map the characters in each token
to indices.</p>
</div></blockquote>
<p><strong>character_tokenizer</strong> : <code class="docutils literal"><span class="pre">CharacterTokenizer</span></code>, optional (default=``CharacterTokenizer()``)</p>
<blockquote class="last">
<div><p>We use a <code class="xref py py-class docutils literal"><span class="pre">CharacterTokenizer</span></code> to handle splitting tokens into characters, as it has
options for byte encoding and other things.  The default here is to instantiate a
<code class="docutils literal"><span class="pre">CharacterTokenizer</span></code> with its default parameters, which uses unicode characters and
retains casing.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer.count_vocab_items">
<code class="descname">count_vocab_items</code><span class="sig-paren">(</span><em>token: allennlp.data.tokenizers.token.Token, counter: typing.Dict[str, typing.Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/token_characters_indexer.py#L38-L46"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>The <code class="xref py py-class docutils literal"><span class="pre">Vocabulary</span></code> needs to assign indices to whatever strings we see in the training
data (possibly doing some frequency filtering and using an OOV token).  This method takes
a token and a dictionary of counts and increments counts for whatever vocabulary items are
present in the token.  If this is a single token ID representation, the vocabulary item is
likely the token itself.  If this is a token characters representation, the vocabulary
items are all of the characters in the token.</p>
</dd></dl>

<dl class="classmethod">
<dt id="allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/token_characters_indexer.py#L93-L110"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer.from_params" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>namespace</strong> : <code class="docutils literal"><span class="pre">str</span></code>, optional (default=``token_characters``)</p>
<blockquote>
<div><p>We will use this namespace in the <code class="xref py py-class docutils literal"><span class="pre">Vocabulary</span></code> to map the characters in each token
to indices.</p>
</div></blockquote>
<p><strong>character_tokenizer</strong> : <code class="docutils literal"><span class="pre">Params</span></code>, optional (default=``Params({})``)</p>
<blockquote class="last">
<div><p>We use a <code class="xref py py-class docutils literal"><span class="pre">CharacterTokenizer</span></code> to handle splitting tokens into characters, as it has
options for byte encoding and other things.  These parameters get passed to the character
tokenizer.  The default is to use unicode characters and to retain casing.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer.get_padding_lengths">
<code class="descname">get_padding_lengths</code><span class="sig-paren">(</span><em>token: typing.List[int]</em><span class="sig-paren">)</span> &#x2192; typing.Dict[str, int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/token_characters_indexer.py#L63-L65"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>This method returns a padding dictionary for the given token.  For single ID tokens, e.g.,
this dictionary will be empty, but for a token characters representation, this will return
the number of characters in the token.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer.get_padding_token">
<code class="descname">get_padding_token</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; typing.List[int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/token_characters_indexer.py#L67-L69"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer.get_padding_token" title="Permalink to this definition">¶</a></dt>
<dd><p>When we need to add padding tokens, what should they look like?  This method returns a
&#8220;blank&#8221; token of whatever type is returned by <a class="reference internal" href="#allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer.token_to_indices" title="allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer.token_to_indices"><code class="xref py py-func docutils literal"><span class="pre">token_to_indices()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer.pad_token_sequence">
<code class="descname">pad_token_sequence</code><span class="sig-paren">(</span><em>tokens: typing.List[typing.List[int]], desired_num_tokens: int, padding_lengths: typing.Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; typing.List[typing.List[int]]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/token_characters_indexer.py#L71-L91"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer.pad_token_sequence" title="Permalink to this definition">¶</a></dt>
<dd><p>This method pads a list of tokens to <code class="docutils literal"><span class="pre">desired_num_tokens</span></code>, including any necessary
internal padding using whatever lengths are relevant in <code class="docutils literal"><span class="pre">padding_lengths</span></code>, returning a
padded copy of the input list.  If each token is a single ID, this just adds 0 to the
sequence (or truncates the sequence, if necessary).  If each token is, e.g., a list of
characters, this method will pad both the characters and the number of tokens.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer.token_to_indices">
<code class="descname">token_to_indices</code><span class="sig-paren">(</span><em>token: allennlp.data.tokenizers.token.Token</em>, <em>vocabulary: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span> &#x2192; typing.List[int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/token_characters_indexer.py#L48-L61"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.token_characters_indexer.TokenCharactersIndexer.token_to_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes a string token and converts it into indices in some fashion.  This could be returning
an ID for the token from the vocabulary, or it could be splitting the token into characters
and return a list of IDs for each character from the vocabulary, or something else.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.token_indexers.elmo_indexer"><span id="elmo-indexer"></span></span><dl class="class">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper">
<em class="property">class </em><code class="descclassname">allennlp.data.token_indexers.elmo_indexer.</code><code class="descname">ELMoCharacterMapper</code><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/elmo_indexer.py#L26-L75"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>Maps individual tokens to sequences of character ids, compatible with ELMo.
To be consistent with previously trained models, we include it here as special of existing
character indexers.</p>
<dl class="attribute">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.beginning_of_sentence_character">
<code class="descname">beginning_of_sentence_character</code><em class="property"> = 256</em><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.beginning_of_sentence_character" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.beginning_of_sentence_characters">
<code class="descname">beginning_of_sentence_characters</code><em class="property"> = [258, 256, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260]</em><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.beginning_of_sentence_characters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.beginning_of_word_character">
<code class="descname">beginning_of_word_character</code><em class="property"> = 258</em><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.beginning_of_word_character" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.bos_token">
<code class="descname">bos_token</code><em class="property"> = '&lt;S&gt;'</em><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.bos_token" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="staticmethod">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.convert_word_to_char_ids">
<em class="property">static </em><code class="descname">convert_word_to_char_ids</code><span class="sig-paren">(</span><em>word: str</em><span class="sig-paren">)</span> &#x2192; typing.List[int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/elmo_indexer.py#L60-L75"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.convert_word_to_char_ids" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.end_of_sentence_character">
<code class="descname">end_of_sentence_character</code><em class="property"> = 257</em><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.end_of_sentence_character" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.end_of_sentence_characters">
<code class="descname">end_of_sentence_characters</code><em class="property"> = [258, 257, 259, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260, 260]</em><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.end_of_sentence_characters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.end_of_word_character">
<code class="descname">end_of_word_character</code><em class="property"> = 259</em><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.end_of_word_character" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.eos_token">
<code class="descname">eos_token</code><em class="property"> = '&lt;/S&gt;'</em><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.eos_token" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.max_word_length">
<code class="descname">max_word_length</code><em class="property"> = 50</em><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.max_word_length" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.padding_character">
<code class="descname">padding_character</code><em class="property"> = 260</em><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoCharacterMapper.padding_character" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer">
<em class="property">class </em><code class="descclassname">allennlp.data.token_indexers.elmo_indexer.</code><code class="descname">ELMoTokenCharactersIndexer</code><span class="sig-paren">(</span><em>namespace: str = 'elmo_characters'</em><span class="sig-paren">)</span> &#x2192; None<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/elmo_indexer.py#L79-L135"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.token_indexers.token_indexer.TokenIndexer" title="allennlp.data.token_indexers.token_indexer.TokenIndexer"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.token_indexers.token_indexer.TokenIndexer</span></code></a></p>
<p>Convert a token to an array of character ids to compute ELMo representations.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>namespace</strong> : <code class="docutils literal"><span class="pre">str</span></code>, optional (default=``elmo_characters``)</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.count_vocab_items">
<code class="descname">count_vocab_items</code><span class="sig-paren">(</span><em>token: allennlp.data.tokenizers.token.Token, counter: typing.Dict[str, typing.Dict[str, int]]</em><span class="sig-paren">)</span><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/elmo_indexer.py#L92-L94"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.count_vocab_items" title="Permalink to this definition">¶</a></dt>
<dd><p>The <code class="xref py py-class docutils literal"><span class="pre">Vocabulary</span></code> needs to assign indices to whatever strings we see in the training
data (possibly doing some frequency filtering and using an OOV token).  This method takes
a token and a dictionary of counts and increments counts for whatever vocabulary items are
present in the token.  If this is a single token ID representation, the vocabulary item is
likely the token itself.  If this is a token characters representation, the vocabulary
items are all of the characters in the token.</p>
</dd></dl>

<dl class="classmethod">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/elmo_indexer.py#L126-L135"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.from_params" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>namespace</strong> : <code class="docutils literal"><span class="pre">str</span></code>, optional (default=``elmo_characters``)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.get_padding_lengths">
<code class="descname">get_padding_lengths</code><span class="sig-paren">(</span><em>token: typing.List[int]</em><span class="sig-paren">)</span> &#x2192; typing.Dict[str, int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/elmo_indexer.py#L104-L107"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.get_padding_lengths" title="Permalink to this definition">¶</a></dt>
<dd><p>This method returns a padding dictionary for the given token.  For single ID tokens, e.g.,
this dictionary will be empty, but for a token characters representation, this will return
the number of characters in the token.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.get_padding_token">
<code class="descname">get_padding_token</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; typing.List[int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/elmo_indexer.py#L109-L111"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.get_padding_token" title="Permalink to this definition">¶</a></dt>
<dd><p>When we need to add padding tokens, what should they look like?  This method returns a
&#8220;blank&#8221; token of whatever type is returned by <a class="reference internal" href="#allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.token_to_indices" title="allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.token_to_indices"><code class="xref py py-func docutils literal"><span class="pre">token_to_indices()</span></code></a>.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.pad_token_sequence">
<code class="descname">pad_token_sequence</code><span class="sig-paren">(</span><em>tokens: typing.List[typing.List[int]], desired_num_tokens: int, padding_lengths: typing.Dict[str, int]</em><span class="sig-paren">)</span> &#x2192; typing.List[typing.List[int]]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/elmo_indexer.py#L117-L124"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.pad_token_sequence" title="Permalink to this definition">¶</a></dt>
<dd><p>This method pads a list of tokens to <code class="docutils literal"><span class="pre">desired_num_tokens</span></code>, including any necessary
internal padding using whatever lengths are relevant in <code class="docutils literal"><span class="pre">padding_lengths</span></code>, returning a
padded copy of the input list.  If each token is a single ID, this just adds 0 to the
sequence (or truncates the sequence, if necessary).  If each token is, e.g., a list of
characters, this method will pad both the characters and the number of tokens.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.token_to_indices">
<code class="descname">token_to_indices</code><span class="sig-paren">(</span><em>token: allennlp.data.tokenizers.token.Token</em>, <em>vocabulary: allennlp.data.vocabulary.Vocabulary</em><span class="sig-paren">)</span> &#x2192; typing.List[int]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/token_indexers/elmo_indexer.py#L96-L102"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer.token_to_indices" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes a string token and converts it into indices in some fashion.  This could be returning
an ID for the token from the vocabulary, or it could be splitting the token into characters
and return a list of IDs for each character from the vocabulary, or something else.</p>
</dd></dl>

</dd></dl>

</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="allennlp.data.tokenizers.html" class="btn btn-neutral float-right" title="allennlp.data.tokenizers" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="allennlp.data.iterators.html" class="btn btn-neutral" title="allennlp.data.iterators" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Allen Institute for Artificial Intelligence.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>