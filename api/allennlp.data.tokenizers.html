

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>allennlp.data.tokenizers &mdash; AllenNLP 0.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="AllenNLP 0.0 documentation" href="../index.html"/>
        <link rel="up" title="allennlp.data" href="allennlp.data.html"/>
        <link rel="next" title="allennlp.data.vocabulary" href="allennlp.data.vocabulary.html"/>
        <link rel="prev" title="allennlp.data.token_indexers" href="allennlp.data.token_indexers.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/allennlp-logo-dark.png" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                0.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="allennlp.commands.html">allennlp.commands</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.subcommand.html">allennlp.commands.subcommand</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.evaluate.html">allennlp.commands.evaluate</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.predict.html">allennlp.commands.predict</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.serve.html">allennlp.commands.serve</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.train.html">allennlp.commands.train</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.common.html">allennlp.common</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.checks.html">allennlp.common.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.file_utils.html">allennlp.common.file_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.params.html">allennlp.common.params</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.registrable.html">allennlp.common.registrable</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.squad_eval.html">allennlp.common.squad_eval</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.tee_logger.html">allennlp.common.tee_logger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.testing.html">allennlp.common.testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.util.html">allennlp.common.util</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="allennlp.data.html">allennlp.data</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset.html">allennlp.data.dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset_readers.html">allennlp.data.dataset_readers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.dataset_reader.html">allennlp.data.dataset_readers.dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.conll2003.html">allennlp.data.dataset_readers.conll2003</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.language_modeling.html">allennlp.data.dataset_readers.language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.reading_comprehension.html">allennlp.data.dataset_readers.reading_comprehension</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.coreference_resolution.html">allennlp.data.dataset_readers.coreference_resolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_role_labeling.html">allennlp.data.dataset_readers.semantic_role_labeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.seq2seq.html">allennlp.data.dataset_readers.seq2seq</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.sequence_tagging.html">allennlp.data.dataset_readers.sequence_tagging</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.snli.html">allennlp.data.dataset_readers.snli</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.fields.html">allennlp.data.fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.instance.html">allennlp.data.instance</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.iterators.html">allennlp.data.iterators</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.token_indexers.html">allennlp.data.token_indexers</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">allennlp.data.tokenizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.vocabulary.html">allennlp.data.vocabulary</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.models.html">allennlp.models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.model.html">allennlp.models.model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.archival.html">allennlp.models.archival</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.crf_tagger.html">allennlp.models.crf_tagger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.decomposable_attention.html">allennlp.models.decomposable_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.encoder_decoders.html">allennlp.models.encoder_decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.reading_comprehension.html">allennlp.models.reading_comprehension</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.coreference_resolution.html">allennlp.models.coreference_resolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.semantic_role_labeler.html">allennlp.models.semantic_role_labeler</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.simple_tagger.html">allennlp.models.simple_tagger</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.modules.html">allennlp.modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.attention.html">allennlp.modules.attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.augmented_lstm.html">allennlp.modules.augmented_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.lstm_cell_with_projection.html">allennlp.modules.lstm_cell_with_projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_elmo_lstm.html">allennlp.modules.stacked_elmo_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.conditional_random_field.html">allennlp.modules.conditional_random_field</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.feedforward.html">allennlp.modules.feedforward</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.highway.html">allennlp.modules.highway</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.matrix_attention.html">allennlp.modules.matrix_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2seq_encoders.html">allennlp.modules.seq2seq_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2vec_encoders.html">allennlp.modules.seq2vec_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.similarity_functions.html">allennlp.modules.similarity_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_alternating_lstm.html">allennlp.modules.stacked_alternating_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.text_field_embedders.html">allennlp.modules.text_field_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.time_distributed.html">allennlp.modules.time_distributed</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.token_embedders.html">allennlp.modules.token_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.scalar_mix.html">allennlp.modules.scalar_mix</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.nn.html">allennlp.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.activations.html">allennlp.nn.activations</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.initializers.html">allennlp.nn.initializers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.regularizers.html">allennlp.nn.regularizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.util.html">allennlp.nn.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.service.html">allennlp.service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.db.html">allennlp.service.db</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.permalinks.html">allennlp.service.permalinks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.predictors.html">allennlp.service.predictors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.server_sanic.html">allennlp.service.server_sanic</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.training.html">allennlp.training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.learning_rate_schedulers.html">allennlp.training.learning_rate_schedulers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.metrics.html">allennlp.training.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.optimizers.html">allennlp.training.optimizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer.html">allennlp.training.trainer</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">AllenNLP</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="allennlp.data.html">allennlp.data</a> &raquo;</li>
        
      <li>allennlp.data.tokenizers</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api/allennlp.data.tokenizers.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-allennlp.data.tokenizers.token">
<span id="allennlp-data-tokenizers"></span><h1>allennlp.data.tokenizers<a class="headerlink" href="#module-allennlp.data.tokenizers.token" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="allennlp.data.tokenizers.token.Token">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.token.</code><code class="descname">Token</code><span class="sig-paren">(</span><em>text: str = None</em>, <em>idx: int = None</em>, <em>pos: str = None</em>, <em>tag: str = None</em>, <em>dep: str = None</em>, <em>ent_type: str = None</em>, <em>text_id: int = None</em><span class="sig-paren">)</span> &#x2192; None<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/token.py#L1-L45"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.token.Token" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>A simple token representation, keeping track of the token&#8217;s text, offset in the passage it was
taken from, POS tag, and dependency relation.  These fields match spacy&#8217;s exactly, so we can
just use a spacy token for this.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>text</strong> : <code class="docutils literal"><span class="pre">str</span></code>, optional</p>
<blockquote>
<div><p>The original text represented by this token.</p>
</div></blockquote>
<p><strong>idx</strong> : <code class="docutils literal"><span class="pre">int</span></code>, optional</p>
<blockquote>
<div><p>The character offset of this token into the tokenized passage.</p>
</div></blockquote>
<p><strong>pos</strong> : <code class="docutils literal"><span class="pre">str</span></code>, optional</p>
<blockquote>
<div><p>The coarse-grained part of speech of this token.</p>
</div></blockquote>
<p><strong>tag</strong> : <code class="docutils literal"><span class="pre">str</span></code>, optional</p>
<blockquote>
<div><p>The fine-grained part of speech of this token.</p>
</div></blockquote>
<p><strong>dep</strong> : <code class="docutils literal"><span class="pre">str</span></code>, optional</p>
<blockquote>
<div><p>The dependency relation for this token.</p>
</div></blockquote>
<p><strong>ent_type</strong> : <code class="docutils literal"><span class="pre">str</span></code>, optional</p>
<blockquote>
<div><p>The entity type (i.e., the NER tag) for this token.</p>
</div></blockquote>
<p><strong>text_id</strong> : <code class="docutils literal"><span class="pre">int</span></code>, optional</p>
<blockquote class="last">
<div><p>If your tokenizer returns integers instead of strings (e.g., because you&#8217;re doing byte
encoding, or some hash-based embedding), set this with the integer.  If this is set, we
will bypass the vocabulary when indexing this token, regardless of whether <code class="docutils literal"><span class="pre">text</span></code> is also
set.  You can <cite>also</cite> set <code class="docutils literal"><span class="pre">text</span></code> with the original text, if you want, so that you can
still use a character-level representation in addition to a hash-based word embedding.</p>
<p>The other fields on <code class="docutils literal"><span class="pre">Token</span></code> follow the fields on spacy&#8217;s <code class="docutils literal"><span class="pre">Token</span></code> object; this is one we
added, similar to spacy&#8217;s <code class="docutils literal"><span class="pre">lex_id</span></code>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<span class="target" id="module-allennlp.data.tokenizers"></span><p>This module contains various classes for performing
tokenization, stemming, and filtering.</p>
<ul class="simple">
<li><a class="reference internal" href="#tokenizer"><span class="std std-ref">Tokenizer</span></a></li>
<li><a class="reference internal" href="#word-tokenizer"><span class="std std-ref">WordTokenizer</span></a></li>
<li><a class="reference internal" href="#character-tokenizer"><span class="std std-ref">CharacterTokenizer</span></a></li>
<li><a class="reference internal" href="#word-filter"><span class="std std-ref">WordFilter</span></a></li>
<li><a class="reference internal" href="#word-splitter"><span class="std std-ref">WordSplitter</span></a></li>
<li><a class="reference internal" href="#word-stemmer"><span class="std std-ref">WordStemmer</span></a></li>
</ul>
<span class="target" id="module-allennlp.data.tokenizers.tokenizer"><span id="tokenizer"></span></span><dl class="class">
<dt id="allennlp.data.tokenizers.tokenizer.Tokenizer">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.tokenizer.</code><code class="descname">Tokenizer</code><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/tokenizer.py#L7-L39"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.tokenizer.Tokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="allennlp.common.registrable.html#allennlp.common.registrable.Registrable" title="allennlp.common.registrable.Registrable"><code class="xref py py-class docutils literal"><span class="pre">allennlp.common.registrable.Registrable</span></code></a></p>
<p>A <code class="docutils literal"><span class="pre">Tokenizer</span></code> splits strings of text into tokens.  Typically, this either splits text into
word tokens or character tokens, and those are the two tokenizer subclasses we have implemented
here, though you could imagine wanting to do other kinds of tokenization for structured or
other inputs.</p>
<p>As part of tokenization, concrete implementations of this API will also handle stemming,
stopword filtering, adding start and end tokens, or other kinds of things you might want to do
to your tokens.  See the parameters to, e.g., <a class="reference internal" href="#allennlp.data.tokenizers.word_tokenizer.WordTokenizer" title="allennlp.data.tokenizers.word_tokenizer.WordTokenizer"><code class="xref py py-class docutils literal"><span class="pre">WordTokenizer</span></code></a>, or whichever tokenizer
you want to use.</p>
<p>If the base input to your model is words, you should use a <a class="reference internal" href="#allennlp.data.tokenizers.word_tokenizer.WordTokenizer" title="allennlp.data.tokenizers.word_tokenizer.WordTokenizer"><code class="xref py py-class docutils literal"><span class="pre">WordTokenizer</span></code></a>, even if
you also want to have a character-level encoder to get an additional vector for each word
token.  Splitting word tokens into character arrays is handled separately, in the
<code class="xref py py-class docutils literal"><span class="pre">token_representations.TokenRepresentation</span></code> class.</p>
<dl class="attribute">
<dt id="allennlp.data.tokenizers.tokenizer.Tokenizer.default_implementation">
<code class="descname">default_implementation</code><em class="property"> = 'word'</em><a class="headerlink" href="#allennlp.data.tokenizers.tokenizer.Tokenizer.default_implementation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="allennlp.data.tokenizers.tokenizer.Tokenizer.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.tokenizers.tokenizer.Tokenizer<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/tokenizer.py#L36-L39"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.tokenizer.Tokenizer.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.tokenizers.tokenizer.Tokenizer.tokenize">
<code class="descname">tokenize</code><span class="sig-paren">(</span><em>text: str</em><span class="sig-paren">)</span> &#x2192; typing.List[allennlp.data.tokenizers.token.Token]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/tokenizer.py#L26-L34"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.tokenizer.Tokenizer.tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>The only public method for this class.  Actually implements splitting words into tokens.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>tokens</strong> : <code class="docutils literal"><span class="pre">List[Token]</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.tokenizers.word_tokenizer"><span id="word-tokenizer"></span></span><dl class="class">
<dt id="allennlp.data.tokenizers.word_tokenizer.WordTokenizer">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.word_tokenizer.</code><code class="descname">WordTokenizer</code><span class="sig-paren">(</span><em>word_splitter: allennlp.data.tokenizers.word_splitter.WordSplitter = None</em>, <em>word_filter: allennlp.data.tokenizers.word_filter.WordFilter = &lt;allennlp.data.tokenizers.word_filter.PassThroughWordFilter object&gt;</em>, <em>word_stemmer: allennlp.data.tokenizers.word_stemmer.WordStemmer = &lt;allennlp.data.tokenizers.word_stemmer.PassThroughWordStemmer object&gt;</em>, <em>start_tokens: typing.List[str] = None</em>, <em>end_tokens: typing.List[str] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_tokenizer.py#L14-L96"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_tokenizer.WordTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.tokenizers.tokenizer.Tokenizer" title="allennlp.data.tokenizers.tokenizer.Tokenizer"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.tokenizers.tokenizer.Tokenizer</span></code></a></p>
<p>A <code class="docutils literal"><span class="pre">WordTokenizer</span></code> handles the splitting of strings into words as well as any desired
post-processing (e.g., stemming, filtering, etc.).  Note that we leave one particular piece of
post-processing for later: the decision of whether or not to lowercase the token.  This is for
two reasons: (1) if you want to make two different casing decisions for whatever reason, you
won&#8217;t have to run the tokenizer twice, and more importantly (2) if you want to lowercase words
for your word embedding, but retain capitalization in a character-level representation, we need
to retain the capitalization here.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>word_splitter</strong> : <code class="docutils literal"><span class="pre">WordSplitter</span></code>, optional</p>
<blockquote>
<div><p>The <code class="xref py py-class docutils literal"><span class="pre">WordSplitter</span></code> to use for splitting text strings into word tokens.  The default
is to use the <code class="docutils literal"><span class="pre">SpacyWordSplitter</span></code> with default parameters.</p>
</div></blockquote>
<p><strong>word_filter</strong> : <code class="docutils literal"><span class="pre">WordFilter</span></code>, optional</p>
<blockquote>
<div><p>The <code class="xref py py-class docutils literal"><span class="pre">WordFilter</span></code> to use for, e.g., removing stopwords.  Default is to do no
filtering.</p>
</div></blockquote>
<p><strong>word_stemmer</strong> : <code class="docutils literal"><span class="pre">WordStemmer</span></code>, optional</p>
<blockquote>
<div><p>The <code class="xref py py-class docutils literal"><span class="pre">WordStemmer</span></code> to use.  Default is no stemming.</p>
</div></blockquote>
<p><strong>start_tokens</strong> : <code class="docutils literal"><span class="pre">List[str]</span></code>, optional</p>
<blockquote>
<div><p>If given, these tokens will be added to the beginning of every string we tokenize.</p>
</div></blockquote>
<p><strong>end_tokens</strong> : <code class="docutils literal"><span class="pre">List[str]</span></code>, optional</p>
<blockquote>
<div><p>If given, these tokens will be added to the end of every string we tokenize.</p>
</div></blockquote>
<p><strong>language</strong> : <code class="docutils literal"><span class="pre">str</span></code>, optional</p>
<blockquote>
<div><p>We use spacy to tokenize strings; this option specifies which language to use.  By default
we use English.</p>
</div></blockquote>
<p><strong>pos_tags</strong> : <code class="docutils literal"><span class="pre">bool</span></code>, optional</p>
<blockquote>
<div><p>By default we do not load spacy&#8217;s tagging model, to save loading time and memory.  Set this
to <code class="docutils literal"><span class="pre">True</span></code> if you want to have access to spacy&#8217;s POS tags in the returned tokens.</p>
</div></blockquote>
<p><strong>parse</strong> : <code class="docutils literal"><span class="pre">bool</span></code>, optional</p>
<blockquote>
<div><p>By default we do not load spacy&#8217;s parsing model, to save loading time and memory.  Set this
to <code class="docutils literal"><span class="pre">True</span></code> if you want to have access to spacy&#8217;s dependency parse tags in the returned
tokens.</p>
</div></blockquote>
<p><strong>ner</strong> : <code class="docutils literal"><span class="pre">bool</span></code>, optional</p>
<blockquote class="last">
<div><p>By default we do not load spacy&#8217;s parsing model, to save loading time and memory.  Set this
to <code class="docutils literal"><span class="pre">True</span></code> if you want to have access to spacy&#8217;s NER tags in the returned tokens.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="classmethod">
<dt id="allennlp.data.tokenizers.word_tokenizer.WordTokenizer.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.tokenizers.word_tokenizer.WordTokenizer<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_tokenizer.py#L84-L96"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_tokenizer.WordTokenizer.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.tokenizers.word_tokenizer.WordTokenizer.tokenize">
<code class="descname">tokenize</code><span class="sig-paren">(</span><em>text: str</em><span class="sig-paren">)</span> &#x2192; typing.List[allennlp.data.tokenizers.token.Token]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_tokenizer.py#L67-L82"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_tokenizer.WordTokenizer.tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Does whatever processing is required to convert a string of text into a sequence of tokens.</p>
<p>At a minimum, this uses a <code class="docutils literal"><span class="pre">WordSplitter</span></code> to split words into text.  It may also do
stemming or stopword removal, depending on the parameters given to the constructor.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.tokenizers.character_tokenizer"><span id="character-tokenizer"></span></span><dl class="class">
<dt id="allennlp.data.tokenizers.character_tokenizer.CharacterTokenizer">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.character_tokenizer.</code><code class="descname">CharacterTokenizer</code><span class="sig-paren">(</span><em>byte_encoding: str = None</em>, <em>lowercase_characters: bool = False</em>, <em>start_tokens: typing.List[str] = None</em>, <em>end_tokens: typing.List[str] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/character_tokenizer.py#L11-L83"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.character_tokenizer.CharacterTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.tokenizers.tokenizer.Tokenizer" title="allennlp.data.tokenizers.tokenizer.Tokenizer"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.tokenizers.tokenizer.Tokenizer</span></code></a></p>
<p>A <code class="docutils literal"><span class="pre">CharacterTokenizer</span></code> splits strings into character tokens.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>byte_encoding</strong> : str, optional (default=``None``)</p>
<blockquote>
<div><p>If not <code class="docutils literal"><span class="pre">None</span></code>, we will use this encoding to encode the string as bytes, and use the byte
sequence as characters, instead of the unicode characters in the python string.  E.g., the
character &#8216;á&#8217; would be a single token if this option is <code class="docutils literal"><span class="pre">None</span></code>, but it would be two
tokens if this option is set to <code class="docutils literal"><span class="pre">&quot;utf-8&quot;</span></code>.</p>
<p>If this is not <code class="docutils literal"><span class="pre">None</span></code>, <code class="docutils literal"><span class="pre">tokenize</span></code> will return a <code class="docutils literal"><span class="pre">List[int]</span></code> instead of a
<code class="docutils literal"><span class="pre">List[str]</span></code>, and we will bypass the vocabulary in the <code class="docutils literal"><span class="pre">TokenIndexer</span></code>.</p>
</div></blockquote>
<p><strong>lowercase_characters</strong> : <code class="docutils literal"><span class="pre">bool</span></code>, optional (default=``False``)</p>
<blockquote>
<div><p>If <code class="docutils literal"><span class="pre">True</span></code>, we will lowercase all of the characters in the text before doing any other
operation.  You probably do not want to do this, as character vocabularies are generally
not very large to begin with, but it&#8217;s an option if you really want it.</p>
</div></blockquote>
<p><strong>start_tokens</strong> : <code class="docutils literal"><span class="pre">List[str]</span></code>, optional</p>
<blockquote>
<div><p>If given, these tokens will be added to the beginning of every string we tokenize.  If
using byte encoding, this should actually be a <code class="docutils literal"><span class="pre">List[int]</span></code>, not a <code class="docutils literal"><span class="pre">List[str]</span></code>.</p>
</div></blockquote>
<p><strong>end_tokens</strong> : <code class="docutils literal"><span class="pre">List[str]</span></code>, optional</p>
<blockquote class="last">
<div><p>If given, these tokens will be added to the end of every string we tokenize.  If using byte
encoding, this should actually be a <code class="docutils literal"><span class="pre">List[int]</span></code>, not a <code class="docutils literal"><span class="pre">List[str]</span></code>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="classmethod">
<dt id="allennlp.data.tokenizers.character_tokenizer.CharacterTokenizer.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.tokenizers.character_tokenizer.CharacterTokenizer<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/character_tokenizer.py#L73-L83"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.character_tokenizer.CharacterTokenizer.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.tokenizers.character_tokenizer.CharacterTokenizer.tokenize">
<code class="descname">tokenize</code><span class="sig-paren">(</span><em>text: str</em><span class="sig-paren">)</span> &#x2192; typing.List[allennlp.data.tokenizers.token.Token]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/character_tokenizer.py#L49-L71"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.character_tokenizer.CharacterTokenizer.tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>The only public method for this class.  Actually implements splitting words into tokens.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>tokens</strong> : <code class="docutils literal"><span class="pre">List[Token]</span></code></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.tokenizers.word_filter"><span id="word-filter"></span></span><dl class="class">
<dt id="allennlp.data.tokenizers.word_filter.PassThroughWordFilter">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.word_filter.</code><code class="descname">PassThroughWordFilter</code><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_filter.py#L33-L39"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_filter.PassThroughWordFilter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.tokenizers.word_filter.WordFilter" title="allennlp.data.tokenizers.word_filter.WordFilter"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.tokenizers.word_filter.WordFilter</span></code></a></p>
<p>Does not filter words; it&#8217;s a no-op.  This is the default word filter.</p>
<dl class="method">
<dt id="allennlp.data.tokenizers.word_filter.PassThroughWordFilter.filter_words">
<code class="descname">filter_words</code><span class="sig-paren">(</span><em>words: typing.List[allennlp.data.tokenizers.token.Token]</em><span class="sig-paren">)</span> &#x2192; typing.List[allennlp.data.tokenizers.token.Token]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_filter.py#L37-L39"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_filter.PassThroughWordFilter.filter_words" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a filtered list of words.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="allennlp.data.tokenizers.word_filter.StopwordFilter">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.word_filter.</code><code class="descname">StopwordFilter</code><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_filter.py#L43-L76"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_filter.StopwordFilter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.tokenizers.word_filter.WordFilter" title="allennlp.data.tokenizers.word_filter.WordFilter"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.tokenizers.word_filter.WordFilter</span></code></a></p>
<p>Uses a list of stopwords to filter.</p>
<dl class="method">
<dt id="allennlp.data.tokenizers.word_filter.StopwordFilter.filter_words">
<code class="descname">filter_words</code><span class="sig-paren">(</span><em>words: typing.List[allennlp.data.tokenizers.token.Token]</em><span class="sig-paren">)</span> &#x2192; typing.List[allennlp.data.tokenizers.token.Token]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_filter.py#L74-L76"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_filter.StopwordFilter.filter_words" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a filtered list of words.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="allennlp.data.tokenizers.word_filter.WordFilter">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.word_filter.</code><code class="descname">WordFilter</code><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_filter.py#L9-L29"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_filter.WordFilter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="allennlp.common.registrable.html#allennlp.common.registrable.Registrable" title="allennlp.common.registrable.Registrable"><code class="xref py py-class docutils literal"><span class="pre">allennlp.common.registrable.Registrable</span></code></a></p>
<p>A <code class="docutils literal"><span class="pre">WordFilter</span></code> removes words from a token list.  Typically, this is for stopword removal,
though you could feasibly use it for more domain-specific removal if you want.</p>
<p>Word removal happens <cite>before</cite> stemming, so keep that in mind if you&#8217;re designing a list of
words to be removed.</p>
<dl class="attribute">
<dt id="allennlp.data.tokenizers.word_filter.WordFilter.default_implementation">
<code class="descname">default_implementation</code><em class="property"> = 'pass_through'</em><a class="headerlink" href="#allennlp.data.tokenizers.word_filter.WordFilter.default_implementation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.tokenizers.word_filter.WordFilter.filter_words">
<code class="descname">filter_words</code><span class="sig-paren">(</span><em>words: typing.List[allennlp.data.tokenizers.token.Token]</em><span class="sig-paren">)</span> &#x2192; typing.List[allennlp.data.tokenizers.token.Token]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_filter.py#L19-L23"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_filter.WordFilter.filter_words" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a filtered list of words.</p>
</dd></dl>

<dl class="classmethod">
<dt id="allennlp.data.tokenizers.word_filter.WordFilter.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.tokenizers.word_filter.WordFilter<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_filter.py#L25-L29"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_filter.WordFilter.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.tokenizers.word_splitter"><span id="word-splitter"></span></span><dl class="class">
<dt id="allennlp.data.tokenizers.word_splitter.JustSpacesWordSplitter">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.word_splitter.</code><code class="descname">JustSpacesWordSplitter</code><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L119-L136"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.JustSpacesWordSplitter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.tokenizers.word_splitter.WordSplitter" title="allennlp.data.tokenizers.word_splitter.WordSplitter"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.tokenizers.word_splitter.WordSplitter</span></code></a></p>
<p>A <code class="docutils literal"><span class="pre">WordSplitter</span></code> that assumes you&#8217;ve already done your own tokenization somehow and have
separated the tokens by spaces.  We just split the input string on whitespace and return the
resulting list.  We use a somewhat odd name here to avoid coming too close to the more
commonly used <code class="docutils literal"><span class="pre">SpacyWordSplitter</span></code>.</p>
<p>Note that we use <code class="docutils literal"><span class="pre">sentence.split()</span></code>, which means that the amount of whitespace between the
tokens does not matter.  This will never result in spaces being included as tokens.</p>
<dl class="classmethod">
<dt id="allennlp.data.tokenizers.word_splitter.JustSpacesWordSplitter.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.tokenizers.word_splitter.WordSplitter<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L133-L136"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.JustSpacesWordSplitter.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.tokenizers.word_splitter.JustSpacesWordSplitter.split_words">
<code class="descname">split_words</code><span class="sig-paren">(</span><em>sentence: str</em><span class="sig-paren">)</span> &#x2192; typing.List[allennlp.data.tokenizers.token.Token]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L129-L131"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.JustSpacesWordSplitter.split_words" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits <code class="docutils literal"><span class="pre">sentence</span></code> into a list of <code class="xref py py-class docutils literal"><span class="pre">Token</span></code> objects.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="allennlp.data.tokenizers.word_splitter.LettersDigitsWordSplitter">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.word_splitter.</code><code class="descname">LettersDigitsWordSplitter</code><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L100-L115"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.LettersDigitsWordSplitter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.tokenizers.word_splitter.WordSplitter" title="allennlp.data.tokenizers.word_splitter.WordSplitter"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.tokenizers.word_splitter.WordSplitter</span></code></a></p>
<p>A <code class="docutils literal"><span class="pre">WordSplitter</span></code> which keeps runs of (unicode) letters and runs of digits together, while
every other non-whitespace character becomes a separate word.</p>
<dl class="classmethod">
<dt id="allennlp.data.tokenizers.word_splitter.LettersDigitsWordSplitter.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.tokenizers.word_splitter.WordSplitter<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L112-L115"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.LettersDigitsWordSplitter.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.tokenizers.word_splitter.LettersDigitsWordSplitter.split_words">
<code class="descname">split_words</code><span class="sig-paren">(</span><em>sentence: str</em><span class="sig-paren">)</span> &#x2192; typing.List[allennlp.data.tokenizers.token.Token]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L105-L110"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.LettersDigitsWordSplitter.split_words" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits <code class="docutils literal"><span class="pre">sentence</span></code> into a list of <code class="xref py py-class docutils literal"><span class="pre">Token</span></code> objects.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="allennlp.data.tokenizers.word_splitter.NltkWordSplitter">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.word_splitter.</code><code class="descname">NltkWordSplitter</code><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L140-L157"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.NltkWordSplitter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.tokenizers.word_splitter.WordSplitter" title="allennlp.data.tokenizers.word_splitter.WordSplitter"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.tokenizers.word_splitter.WordSplitter</span></code></a></p>
<p>A <code class="docutils literal"><span class="pre">WordSplitter</span></code> that uses nltk&#8217;s <code class="docutils literal"><span class="pre">word_tokenize</span></code> method.</p>
<p>I found that nltk is very slow, so I switched to using my own simple one, which is a good deal
faster.  But I&#8217;m adding this one back so that there&#8217;s consistency with older versions of the
code, if you really want it.</p>
<dl class="classmethod">
<dt id="allennlp.data.tokenizers.word_splitter.NltkWordSplitter.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.tokenizers.word_splitter.WordSplitter<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L154-L157"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.NltkWordSplitter.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.tokenizers.word_splitter.NltkWordSplitter.split_words">
<code class="descname">split_words</code><span class="sig-paren">(</span><em>sentence: str</em><span class="sig-paren">)</span> &#x2192; typing.List[allennlp.data.tokenizers.token.Token]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L148-L152"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.NltkWordSplitter.split_words" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits <code class="docutils literal"><span class="pre">sentence</span></code> into a list of <code class="xref py py-class docutils literal"><span class="pre">Token</span></code> objects.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="allennlp.data.tokenizers.word_splitter.SimpleWordSplitter">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.word_splitter.</code><code class="descname">SimpleWordSplitter</code><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L33-L96"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.SimpleWordSplitter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.tokenizers.word_splitter.WordSplitter" title="allennlp.data.tokenizers.word_splitter.WordSplitter"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.tokenizers.word_splitter.WordSplitter</span></code></a></p>
<p>Does really simple tokenization.  NLTK was too slow, so we wrote our own simple tokenizer
instead.  This just does an initial split(), followed by some heuristic filtering of each
whitespace-delimited token, separating contractions and punctuation.  We assume lower-cased,
reasonably well-formed English sentences as input.</p>
<dl class="classmethod">
<dt id="allennlp.data.tokenizers.word_splitter.SimpleWordSplitter.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.tokenizers.word_splitter.WordSplitter<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L93-L96"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.SimpleWordSplitter.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.tokenizers.word_splitter.SimpleWordSplitter.split_words">
<code class="descname">split_words</code><span class="sig-paren">(</span><em>sentence: str</em><span class="sig-paren">)</span> &#x2192; typing.List[allennlp.data.tokenizers.token.Token]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L48-L88"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.SimpleWordSplitter.split_words" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits a sentence into word tokens.  We handle four kinds of things: words with punctuation
that should be ignored as a special case (Mr. Mrs., etc.), contractions/genitives (isn&#8217;t,
don&#8217;t, Matt&#8217;s), and beginning and ending punctuation (&#8220;antennagate&#8221;, (parentheticals), and
such.).</p>
<p>The basic outline is to split on whitespace, then check each of these cases.  First, we
strip off beginning punctuation, then strip off ending punctuation, then strip off
contractions.  When we strip something off the beginning of a word, we can add it to the
list of tokens immediately.  When we strip it off the end, we have to save it to be added
to after the word itself has been added.  Before stripping off any part of a token, we
first check to be sure the token isn&#8217;t in our list of special cases.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="allennlp.data.tokenizers.word_splitter.SpacyWordSplitter">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.word_splitter.</code><code class="descname">SpacyWordSplitter</code><span class="sig-paren">(</span><em>language: str = 'en_core_web_sm'</em>, <em>pos_tags: bool = False</em>, <em>parse: bool = False</em>, <em>ner: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L161-L184"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.SpacyWordSplitter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.tokenizers.word_splitter.WordSplitter" title="allennlp.data.tokenizers.word_splitter.WordSplitter"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.tokenizers.word_splitter.WordSplitter</span></code></a></p>
<p>A <code class="docutils literal"><span class="pre">WordSplitter</span></code> that uses spaCy&#8217;s tokenizer.  It&#8217;s fast and reasonable - this is the
recommended <code class="docutils literal"><span class="pre">WordSplitter</span></code>.</p>
<dl class="classmethod">
<dt id="allennlp.data.tokenizers.word_splitter.SpacyWordSplitter.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.tokenizers.word_splitter.WordSplitter<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L177-L184"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.SpacyWordSplitter.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.tokenizers.word_splitter.SpacyWordSplitter.split_words">
<code class="descname">split_words</code><span class="sig-paren">(</span><em>sentence: str</em><span class="sig-paren">)</span> &#x2192; typing.List[allennlp.data.tokenizers.token.Token]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L173-L175"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.SpacyWordSplitter.split_words" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits <code class="docutils literal"><span class="pre">sentence</span></code> into a list of <code class="xref py py-class docutils literal"><span class="pre">Token</span></code> objects.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="allennlp.data.tokenizers.word_splitter.WordSplitter">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.word_splitter.</code><code class="descname">WordSplitter</code><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L11-L29"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.WordSplitter" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="allennlp.common.registrable.html#allennlp.common.registrable.Registrable" title="allennlp.common.registrable.Registrable"><code class="xref py py-class docutils literal"><span class="pre">allennlp.common.registrable.Registrable</span></code></a></p>
<p>A <code class="docutils literal"><span class="pre">WordSplitter</span></code> splits strings into words.  This is typically called a &#8220;tokenizer&#8221; in NLP,
because splitting strings into characters is trivial, but we use <code class="docutils literal"><span class="pre">Tokenizer</span></code> to refer to the
higher-level object that splits strings into tokens (which could just be character tokens).
So, we&#8217;re using &#8220;word splitter&#8221; here for this.</p>
<dl class="attribute">
<dt id="allennlp.data.tokenizers.word_splitter.WordSplitter.default_implementation">
<code class="descname">default_implementation</code><em class="property"> = 'spacy'</em><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.WordSplitter.default_implementation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="allennlp.data.tokenizers.word_splitter.WordSplitter.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.tokenizers.word_splitter.WordSplitter<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L26-L29"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.WordSplitter.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.tokenizers.word_splitter.WordSplitter.split_words">
<code class="descname">split_words</code><span class="sig-paren">(</span><em>sentence: str</em><span class="sig-paren">)</span> &#x2192; typing.List[allennlp.data.tokenizers.token.Token]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_splitter.py#L20-L24"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_splitter.WordSplitter.split_words" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits <code class="docutils literal"><span class="pre">sentence</span></code> into a list of <code class="xref py py-class docutils literal"><span class="pre">Token</span></code> objects.</p>
</dd></dl>

</dd></dl>

<span class="target" id="module-allennlp.data.tokenizers.word_stemmer"><span id="word-stemmer"></span></span><dl class="class">
<dt id="allennlp.data.tokenizers.word_stemmer.PassThroughWordStemmer">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.word_stemmer.</code><code class="descname">PassThroughWordStemmer</code><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_stemmer.py#L34-L40"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_stemmer.PassThroughWordStemmer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.tokenizers.word_stemmer.WordStemmer" title="allennlp.data.tokenizers.word_stemmer.WordStemmer"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.tokenizers.word_stemmer.WordStemmer</span></code></a></p>
<p>Does not stem words; it&#8217;s a no-op.  This is the default word stemmer.</p>
<dl class="method">
<dt id="allennlp.data.tokenizers.word_stemmer.PassThroughWordStemmer.stem_word">
<code class="descname">stem_word</code><span class="sig-paren">(</span><em>word: allennlp.data.tokenizers.token.Token</em><span class="sig-paren">)</span> &#x2192; allennlp.data.tokenizers.token.Token<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_stemmer.py#L38-L40"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_stemmer.PassThroughWordStemmer.stem_word" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <code class="docutils literal"><span class="pre">Token</span></code> with <code class="docutils literal"><span class="pre">word.text</span></code> replaced by a stemmed word.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="allennlp.data.tokenizers.word_stemmer.PorterStemmer">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.word_stemmer.</code><code class="descname">PorterStemmer</code><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_stemmer.py#L44-L54"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_stemmer.PorterStemmer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#allennlp.data.tokenizers.word_stemmer.WordStemmer" title="allennlp.data.tokenizers.word_stemmer.WordStemmer"><code class="xref py py-class docutils literal"><span class="pre">allennlp.data.tokenizers.word_stemmer.WordStemmer</span></code></a></p>
<p>Uses NLTK&#8217;s PorterStemmer to stem words.</p>
<dl class="method">
<dt id="allennlp.data.tokenizers.word_stemmer.PorterStemmer.stem_word">
<code class="descname">stem_word</code><span class="sig-paren">(</span><em>word: allennlp.data.tokenizers.token.Token</em><span class="sig-paren">)</span> &#x2192; allennlp.data.tokenizers.token.Token<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_stemmer.py#L51-L54"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_stemmer.PorterStemmer.stem_word" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <code class="docutils literal"><span class="pre">Token</span></code> with <code class="docutils literal"><span class="pre">word.text</span></code> replaced by a stemmed word.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="allennlp.data.tokenizers.word_stemmer.WordStemmer">
<em class="property">class </em><code class="descclassname">allennlp.data.tokenizers.word_stemmer.</code><code class="descname">WordStemmer</code><a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_stemmer.py#L8-L30"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_stemmer.WordStemmer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="allennlp.common.registrable.html#allennlp.common.registrable.Registrable" title="allennlp.common.registrable.Registrable"><code class="xref py py-class docutils literal"><span class="pre">allennlp.common.registrable.Registrable</span></code></a></p>
<p>A <code class="docutils literal"><span class="pre">WordStemmer</span></code> lemmatizes words.  This means that we map words to their root form, so that,
e.g., &#8220;have&#8221;, &#8220;has&#8221;, and &#8220;had&#8221; all have the same internal representation.</p>
<p>You should think carefully about whether and how much stemming you want in your model.  Kind of
the whole point of using word embeddings is so that you don&#8217;t have to do this, but in a highly
inflected language, or in a low-data setting, you might need it anyway.  The default
<code class="docutils literal"><span class="pre">WordStemmer</span></code> does nothing, just returning the work token as-is.</p>
<dl class="attribute">
<dt id="allennlp.data.tokenizers.word_stemmer.WordStemmer.default_implementation">
<code class="descname">default_implementation</code><em class="property"> = 'pass_through'</em><a class="headerlink" href="#allennlp.data.tokenizers.word_stemmer.WordStemmer.default_implementation" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="classmethod">
<dt id="allennlp.data.tokenizers.word_stemmer.WordStemmer.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.data.tokenizers.word_stemmer.WordStemmer<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_stemmer.py#L26-L30"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_stemmer.WordStemmer.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.data.tokenizers.word_stemmer.WordStemmer.stem_word">
<code class="descname">stem_word</code><span class="sig-paren">(</span><em>word: allennlp.data.tokenizers.token.Token</em><span class="sig-paren">)</span> &#x2192; allennlp.data.tokenizers.token.Token<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/data/tokenizers/word_stemmer.py#L20-L24"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.data.tokenizers.word_stemmer.WordStemmer.stem_word" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a new <code class="docutils literal"><span class="pre">Token</span></code> with <code class="docutils literal"><span class="pre">word.text</span></code> replaced by a stemmed word.</p>
</dd></dl>

</dd></dl>

</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="allennlp.data.vocabulary.html" class="btn btn-neutral float-right" title="allennlp.data.vocabulary" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="allennlp.data.token_indexers.html" class="btn btn-neutral" title="allennlp.data.token_indexers" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Allen Institute for Artificial Intelligence.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>