

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>allennlp.models.model &mdash; AllenNLP 0.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="AllenNLP 0.0 documentation" href="../index.html"/>
        <link rel="up" title="allennlp.models" href="allennlp.models.html"/>
        <link rel="next" title="allennlp.models.archival" href="allennlp.models.archival.html"/>
        <link rel="prev" title="allennlp.models" href="allennlp.models.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/allennlp-logo-dark.png" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                0.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="allennlp.commands.html">allennlp.commands</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.subcommand.html">allennlp.commands.subcommand</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.evaluate.html">allennlp.commands.evaluate</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.predict.html">allennlp.commands.predict</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.serve.html">allennlp.commands.serve</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.train.html">allennlp.commands.train</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.common.html">allennlp.common</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.checks.html">allennlp.common.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.file_utils.html">allennlp.common.file_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.params.html">allennlp.common.params</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.registrable.html">allennlp.common.registrable</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.squad_eval.html">allennlp.common.squad_eval</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.tee_logger.html">allennlp.common.tee_logger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.testing.html">allennlp.common.testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.util.html">allennlp.common.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.data.html">allennlp.data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset.html">allennlp.data.dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset_readers.html">allennlp.data.dataset_readers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.dataset_reader.html">allennlp.data.dataset_readers.dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.conll2003.html">allennlp.data.dataset_readers.conll2003</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.language_modeling.html">allennlp.data.dataset_readers.language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.reading_comprehension.html">allennlp.data.dataset_readers.reading_comprehension</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.coreference_resolution.html">allennlp.data.dataset_readers.coreference_resolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_role_labeling.html">allennlp.data.dataset_readers.semantic_role_labeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.seq2seq.html">allennlp.data.dataset_readers.seq2seq</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.sequence_tagging.html">allennlp.data.dataset_readers.sequence_tagging</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.snli.html">allennlp.data.dataset_readers.snli</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.fields.html">allennlp.data.fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.instance.html">allennlp.data.instance</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.iterators.html">allennlp.data.iterators</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.token_indexers.html">allennlp.data.token_indexers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.tokenizers.html">allennlp.data.tokenizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.vocabulary.html">allennlp.data.vocabulary</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="allennlp.models.html">allennlp.models</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">allennlp.models.model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.archival.html">allennlp.models.archival</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.crf_tagger.html">allennlp.models.crf_tagger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.decomposable_attention.html">allennlp.models.decomposable_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.encoder_decoders.html">allennlp.models.encoder_decoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.reading_comprehension.html">allennlp.models.reading_comprehension</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.coreference_resolution.html">allennlp.models.coreference_resolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.semantic_role_labeler.html">allennlp.models.semantic_role_labeler</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.simple_tagger.html">allennlp.models.simple_tagger</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.modules.html">allennlp.modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.attention.html">allennlp.modules.attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.augmented_lstm.html">allennlp.modules.augmented_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.lstm_cell_with_projection.html">allennlp.modules.lstm_cell_with_projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_elmo_lstm.html">allennlp.modules.stacked_elmo_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.conditional_random_field.html">allennlp.modules.conditional_random_field</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.feedforward.html">allennlp.modules.feedforward</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.highway.html">allennlp.modules.highway</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.matrix_attention.html">allennlp.modules.matrix_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2seq_encoders.html">allennlp.modules.seq2seq_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2vec_encoders.html">allennlp.modules.seq2vec_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.similarity_functions.html">allennlp.modules.similarity_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_alternating_lstm.html">allennlp.modules.stacked_alternating_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.text_field_embedders.html">allennlp.modules.text_field_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.time_distributed.html">allennlp.modules.time_distributed</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.token_embedders.html">allennlp.modules.token_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.scalar_mix.html">allennlp.modules.scalar_mix</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.nn.html">allennlp.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.activations.html">allennlp.nn.activations</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.initializers.html">allennlp.nn.initializers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.regularizers.html">allennlp.nn.regularizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.util.html">allennlp.nn.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.service.html">allennlp.service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.db.html">allennlp.service.db</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.permalinks.html">allennlp.service.permalinks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.predictors.html">allennlp.service.predictors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.server_sanic.html">allennlp.service.server_sanic</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.training.html">allennlp.training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.learning_rate_schedulers.html">allennlp.training.learning_rate_schedulers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.metrics.html">allennlp.training.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.optimizers.html">allennlp.training.optimizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer.html">allennlp.training.trainer</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">AllenNLP</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="allennlp.models.html">allennlp.models</a> &raquo;</li>
        
      <li>allennlp.models.model</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api/allennlp.models.model.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-allennlp.models.model">
<span id="allennlp-models-model"></span><h1>allennlp.models.model<a class="headerlink" href="#module-allennlp.models.model" title="Permalink to this headline">¶</a></h1>
<p><a class="reference internal" href="#allennlp.models.model.Model" title="allennlp.models.model.Model"><code class="xref py py-class docutils literal"><span class="pre">Model</span></code></a> is an abstract class representing
an AllenNLP model.</p>
<dl class="class">
<dt id="allennlp.models.model.Model">
<em class="property">class </em><code class="descclassname">allennlp.models.model.</code><code class="descname">Model</code><span class="sig-paren">(</span><em>vocab: allennlp.data.vocabulary.Vocabulary</em>, <em>regularizer: allennlp.nn.regularizers.regularizer_applicator.RegularizerApplicator = None</em><span class="sig-paren">)</span> &#x2192; None<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/models/model.py#L26-L253"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.model.Model" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">torch.nn.modules.module.Module</span></code>, <a class="reference internal" href="allennlp.common.registrable.html#allennlp.common.registrable.Registrable" title="allennlp.common.registrable.Registrable"><code class="xref py py-class docutils literal"><span class="pre">allennlp.common.registrable.Registrable</span></code></a></p>
<p>This abstract class represents a model to be trained. Rather than relying completely
on the Pytorch Module, we modify the output spec of <code class="docutils literal"><span class="pre">forward</span></code> to be a dictionary.</p>
<p>Models built using this API are still compatible with other pytorch models and can
be used naturally as modules within other models - outputs are dictionaries, which
can be unpacked and passed into other layers. One caveat to this is that if you
wish to use an AllenNLP model inside a Container (such as nn.Sequential), you must
interleave the models with a wrapper module which unpacks the dictionary into
a list of tensors.</p>
<p>In order for your model to be trained using the <code class="xref py py-class docutils literal"><span class="pre">Trainer</span></code>
api, the output dictionary of your Model must include a &#8220;loss&#8221; key, which will be
optimised during the training process.</p>
<p>Finally, you can optionally implement <a class="reference internal" href="#allennlp.models.model.Model.get_metrics" title="allennlp.models.model.Model.get_metrics"><code class="xref py py-func docutils literal"><span class="pre">Model.get_metrics()</span></code></a> in order to make use
of early stopping and best-model serialization based on a validation metric in
<code class="xref py py-class docutils literal"><span class="pre">Trainer</span></code>.</p>
<dl class="method">
<dt id="allennlp.models.model.Model.decode">
<code class="descname">decode</code><span class="sig-paren">(</span><em>output_dict: typing.Dict[str, torch.FloatTensor]</em><span class="sig-paren">)</span> &#x2192; typing.Dict[str, torch.FloatTensor]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/models/model.py#L158-L173"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.model.Model.decode" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes the result of <a class="reference internal" href="#allennlp.models.model.Model.forward" title="allennlp.models.model.Model.forward"><code class="xref py py-func docutils literal"><span class="pre">forward()</span></code></a> and runs inference / decoding / whatever
post-processing you need to do your model.  The intent is that <code class="docutils literal"><span class="pre">model.forward()</span></code> should
produce potentials or probabilities, and then <code class="docutils literal"><span class="pre">model.decode()</span></code> can take those results and
run some kind of beam search or constrained inference or whatever is necessary.  This does
not handle all possible decoding use cases, but it at least handles simple kinds of
decoding.</p>
<p>This method <cite>modifies</cite> the input dictionary, and also <cite>returns</cite> the same dictionary.</p>
<p>By default in the base class we do nothing.  If your model has some special decoding step,
override this method.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.models.model.Model.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>*inputs</em><span class="sig-paren">)</span> &#x2192; typing.Dict[str, torch.FloatTensor]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/models/model.py#L63-L102"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.model.Model.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the forward pass of the model. In addition, to facilitate easy training,
this method is designed to compute a loss function defined by a user.</p>
<p>The input is comprised of everything required to perform a
training update, <cite>including</cite> labels - you define the signature here!
It is down to the user to ensure that inference can be performed
without the presence of these labels. Hence, any inputs not available at
inference time should only be used inside a conditional block.</p>
<p>The intended sketch of this method is as follows:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="o">....</span>
    <span class="o">....</span>
    <span class="n">output1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer1</span><span class="p">(</span><span class="n">input1</span><span class="p">)</span>
    <span class="n">output2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer2</span><span class="p">(</span><span class="n">input2</span><span class="p">)</span>
    <span class="n">output_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;output1&quot;</span><span class="p">:</span> <span class="n">output1</span><span class="p">,</span> <span class="s2">&quot;output2&quot;</span><span class="p">:</span> <span class="n">output2</span><span class="p">}</span>
    <span class="k">if</span> <span class="n">targets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Function returning a scalar torch.Tensor, defined by the user.</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">output1</span><span class="p">,</span> <span class="n">output2</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
        <span class="n">output_dict</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span>
    <span class="k">return</span> <span class="n">output_dict</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>inputs:</strong></p>
<blockquote>
<div><p>Tensors comprising everything needed to perform a training update, <cite>including</cite> labels,
which should be optional (i.e have a default value of <code class="docutils literal"><span class="pre">None</span></code>).  At inference time,
simply pass the relevant inputs, not including the labels.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">output_dict: <code class="docutils literal"><span class="pre">Dict[str,</span> <span class="pre">torch.Tensor]</span></code></p>
<blockquote class="last">
<div><p>The outputs from the model. In order to train a model using the
<code class="xref py py-class docutils literal"><span class="pre">Trainer</span></code> api, you must provide a &#8220;loss&#8221; key pointing to a
scalar <code class="docutils literal"><span class="pre">torch.Tensor</span></code> representing the loss to be optimized.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="allennlp.models.model.Model.forward_on_instance">
<code class="descname">forward_on_instance</code><span class="sig-paren">(</span><em>instance: allennlp.data.instance.Instance</em>, <em>cuda_device: int</em><span class="sig-paren">)</span> &#x2192; typing.Dict[str, numpy.ndarray]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/models/model.py#L104-L126"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.model.Model.forward_on_instance" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes an <a class="reference internal" href="allennlp.data.instance.html#allennlp.data.instance.Instance" title="allennlp.data.instance.Instance"><code class="xref py py-class docutils literal"><span class="pre">Instance</span></code></a>, which typically has raw text in it,
converts that text into arrays using this model&#8217;s <code class="xref py py-class docutils literal"><span class="pre">Vocabulary</span></code>, passes those arrays
through <code class="xref py py-func docutils literal"><span class="pre">self.forward()</span></code> and <code class="xref py py-func docutils literal"><span class="pre">self.decode()</span></code> (which by default does nothing)
and returns the result.  Before returning the result, we convert any <code class="docutils literal"><span class="pre">torch.autograd.Variables</span></code>
or <code class="docutils literal"><span class="pre">torch.Tensors</span></code> into numpy arrays and remove the batch dimension.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.models.model.Model.forward_on_instances">
<code class="descname">forward_on_instances</code><span class="sig-paren">(</span><em>instances: typing.List[allennlp.data.instance.Instance], cuda_device: int</em><span class="sig-paren">)</span> &#x2192; typing.List[typing.Dict[str, numpy.ndarray]]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/models/model.py#L128-L156"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.model.Model.forward_on_instances" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes a list of  <code class="xref py py-class docutils literal"><span class="pre">Instance`s,</span> <span class="pre">converts</span> <span class="pre">that</span> <span class="pre">text</span> <span class="pre">into</span>
<span class="pre">arrays</span> <span class="pre">using</span> <span class="pre">this</span> <span class="pre">model's</span> <span class="pre">:class:`Vocabulary</span></code>, passes those arrays through
<code class="xref py py-func docutils literal"><span class="pre">self.forward()</span></code> and <code class="xref py py-func docutils literal"><span class="pre">self.decode()</span></code> (which by default does nothing)
and returns the result.  Before returning the result, we convert any
<code class="docutils literal"><span class="pre">torch.autograd.Variables</span></code> or <code class="docutils literal"><span class="pre">torch.Tensors</span></code> into numpy arrays and separate the
batched output into a list of individual dicts per instance. Note that typically
this will be faster on a GPU (and conditionally, on a CPU) than repeated calls to
<a class="reference internal" href="#allennlp.models.model.Model.forward_on_instance" title="allennlp.models.model.Model.forward_on_instance"><code class="xref py py-func docutils literal"><span class="pre">forward_on_instance()</span></code></a>.</p>
</dd></dl>

<dl class="classmethod">
<dt id="allennlp.models.model.Model.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>vocab: allennlp.data.vocabulary.Vocabulary</em>, <em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.models.model.Model<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/models/model.py#L190-L194"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.model.Model.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.models.model.Model.get_metrics">
<code class="descname">get_metrics</code><span class="sig-paren">(</span><em>reset: bool = False</em><span class="sig-paren">)</span> &#x2192; typing.Dict[str, float]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/models/model.py#L175-L188"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.model.Model.get_metrics" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary of metrics. This method will be called by
<code class="xref py py-class docutils literal"><span class="pre">allennlp.training.Trainer</span></code> in order to compute and use model metrics for early
stopping and model serialisation.  We return an empty dictionary here rather than raising
as it is not required to implement metrics for a new model.  A boolean <cite>reset</cite> parameter is
passed, as frequently a metric accumulator will have some state which should be reset
between epochs. This is also compatible with <code class="xref py py-class docutils literal"> <span class="pre">Metrics</span>
<span class="pre">should</span> <span class="pre">be</span> <span class="pre">populated</span> <span class="pre">during</span> <span class="pre">the</span> <span class="pre">call</span> <span class="pre">to</span> <span class="pre">``forward`</span></code>, with the
<code class="xref py py-class docutils literal"><span class="pre">Metric</span></code> handling the accumulation of the metric until this
method is called.</p>
</dd></dl>

<dl class="method">
<dt id="allennlp.models.model.Model.get_regularization_penalty">
<code class="descname">get_regularization_penalty</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; typing.Union[float, torch.autograd.variable.Variable]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/models/model.py#L53-L61"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.model.Model.get_regularization_penalty" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the regularization penalty for the model.
Returns 0 if the model was not configured to use regularization.</p>
</dd></dl>

<dl class="classmethod">
<dt id="allennlp.models.model.Model.load">
<em class="property">classmethod </em><code class="descname">load</code><span class="sig-paren">(</span><em>config: allennlp.common.params.Params</em>, <em>serialization_dir: str</em>, <em>weights_file: str = None</em>, <em>cuda_device: int = -1</em><span class="sig-paren">)</span> &#x2192; allennlp.models.model.Model<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/models/model.py#L196-L253"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.model.Model.load" title="Permalink to this definition">¶</a></dt>
<dd><p>Instantiates an already-trained model, based on the experiment
configuration and some optional overrides.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>config: Params</strong></p>
<blockquote>
<div><p>The configuration that was used to train the model. It should definitely
have a <cite>model</cite> section, and should probably have a <cite>trainer</cite> section
as well.</p>
</div></blockquote>
<p><strong>serialization_dir: str = None</strong></p>
<blockquote>
<div><p>The directory containing the serialized weights, parameters, and vocabulary
of the model.</p>
</div></blockquote>
<p><strong>weights_file: str = None</strong></p>
<blockquote>
<div><p>By default we load the weights from <cite>best.th</cite> in the serialization
directory, but you can override that value here.</p>
</div></blockquote>
<p><strong>cuda_device: int = -1</strong></p>
<blockquote>
<div><p>By default we load the model on the CPU, but if you want to load it
for GPU usage you can specify the id of your GPU here</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">model: Model</p>
<blockquote class="last">
<div><p>The model specified in the configuration, loaded with the serialized
vocabulary and the trained weights.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="allennlp.models.archival.html" class="btn btn-neutral float-right" title="allennlp.models.archival" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="allennlp.models.html" class="btn btn-neutral" title="allennlp.models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Allen Institute for Artificial Intelligence.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>