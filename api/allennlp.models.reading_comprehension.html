

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>allennlp.models.reading_comprehension &mdash; AllenNLP 0.2.2 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="AllenNLP 0.2.2 documentation" href="../index.html"/>
        <link rel="up" title="allennlp.models" href="allennlp.models.html"/>
        <link rel="next" title="allennlp.models.coreference_resolution" href="allennlp.models.coreference_resolution.html"/>
        <link rel="prev" title="allennlp.models.encoder_decoders" href="allennlp.models.encoder_decoders.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/allennlp-logo-dark.png" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                0.2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="allennlp.commands.html">allennlp.commands</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.subcommand.html">allennlp.commands.subcommand</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.evaluate.html">allennlp.commands.evaluate</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.predict.html">allennlp.commands.predict</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.serve.html">allennlp.commands.serve</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.commands.train.html">allennlp.commands.train</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.common.html">allennlp.common</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.checks.html">allennlp.common.checks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.file_utils.html">allennlp.common.file_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.params.html">allennlp.common.params</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.registrable.html">allennlp.common.registrable</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.squad_eval.html">allennlp.common.squad_eval</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.tee_logger.html">allennlp.common.tee_logger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.testing.html">allennlp.common.testing</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.common.util.html">allennlp.common.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.data.html">allennlp.data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset.html">allennlp.data.dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.dataset_readers.html">allennlp.data.dataset_readers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.dataset_reader.html">allennlp.data.dataset_readers.dataset_reader</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.conll2003.html">allennlp.data.dataset_readers.conll2003</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.language_modeling.html">allennlp.data.dataset_readers.language_modeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.reading_comprehension.html">allennlp.data.dataset_readers.reading_comprehension</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.coreference_resolution.html">allennlp.data.dataset_readers.coreference_resolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.semantic_role_labeling.html">allennlp.data.dataset_readers.semantic_role_labeling</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.seq2seq.html">allennlp.data.dataset_readers.seq2seq</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.sequence_tagging.html">allennlp.data.dataset_readers.sequence_tagging</a></li>
<li class="toctree-l3"><a class="reference internal" href="allennlp.data.dataset_readers.snli.html">allennlp.data.dataset_readers.snli</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.fields.html">allennlp.data.fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.instance.html">allennlp.data.instance</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.iterators.html">allennlp.data.iterators</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.token_indexers.html">allennlp.data.token_indexers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.tokenizers.html">allennlp.data.tokenizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.data.vocabulary.html">allennlp.data.vocabulary</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="allennlp.models.html">allennlp.models</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.model.html">allennlp.models.model</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.archival.html">allennlp.models.archival</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.crf_tagger.html">allennlp.models.crf_tagger</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.decomposable_attention.html">allennlp.models.decomposable_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.encoder_decoders.html">allennlp.models.encoder_decoders</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">allennlp.models.reading_comprehension</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.coreference_resolution.html">allennlp.models.coreference_resolution</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.semantic_role_labeler.html">allennlp.models.semantic_role_labeler</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.models.simple_tagger.html">allennlp.models.simple_tagger</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.modules.html">allennlp.modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.attention.html">allennlp.modules.attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.augmented_lstm.html">allennlp.modules.augmented_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.lstm_cell_with_projection.html">allennlp.modules.lstm_cell_with_projection</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.elmo_lstm.html">allennlp.modules.elmo_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.conditional_random_field.html">allennlp.modules.conditional_random_field</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.feedforward.html">allennlp.modules.feedforward</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.highway.html">allennlp.modules.highway</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.matrix_attention.html">allennlp.modules.matrix_attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2seq_encoders.html">allennlp.modules.seq2seq_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.seq2vec_encoders.html">allennlp.modules.seq2vec_encoders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.similarity_functions.html">allennlp.modules.similarity_functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.stacked_alternating_lstm.html">allennlp.modules.stacked_alternating_lstm</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.text_field_embedders.html">allennlp.modules.text_field_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.time_distributed.html">allennlp.modules.time_distributed</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.token_embedders.html">allennlp.modules.token_embedders</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.modules.scalar_mix.html">allennlp.modules.scalar_mix</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.nn.html">allennlp.nn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.activations.html">allennlp.nn.activations</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.initializers.html">allennlp.nn.initializers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.regularizers.html">allennlp.nn.regularizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.nn.util.html">allennlp.nn.util</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.service.html">allennlp.service</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.db.html">allennlp.service.db</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.permalinks.html">allennlp.service.permalinks</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.predictors.html">allennlp.service.predictors</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.service.server_sanic.html">allennlp.service.server_sanic</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="allennlp.training.html">allennlp.training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.learning_rate_schedulers.html">allennlp.training.learning_rate_schedulers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.metrics.html">allennlp.training.metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.optimizers.html">allennlp.training.optimizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="allennlp.training.trainer.html">allennlp.training.trainer</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">AllenNLP</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="allennlp.models.html">allennlp.models</a> &raquo;</li>
        
      <li>allennlp.models.reading_comprehension</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/api/allennlp.models.reading_comprehension.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-allennlp.models.reading_comprehension">
<span id="allennlp-models-reading-comprehension"></span><h1>allennlp.models.reading_comprehension<a class="headerlink" href="#module-allennlp.models.reading_comprehension" title="Permalink to this headline">¶</a></h1>
<p>Reading comprehension is loosely defined as follows: given a question and a passage of text that
contains the answer, answer the question.</p>
<p>These submodules contain models for things that are predominantly focused on reading comprehension.</p>
<span class="target" id="module-allennlp.models.reading_comprehension.bidaf"></span><dl class="class">
<dt id="allennlp.models.reading_comprehension.bidaf.BidirectionalAttentionFlow">
<em class="property">class </em><code class="descclassname">allennlp.models.reading_comprehension.bidaf.</code><code class="descname">BidirectionalAttentionFlow</code><span class="sig-paren">(</span><em>vocab: allennlp.data.vocabulary.Vocabulary</em>, <em>text_field_embedder: allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder</em>, <em>num_highway_layers: int</em>, <em>phrase_layer: allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder</em>, <em>attention_similarity_function: allennlp.modules.similarity_functions.similarity_function.SimilarityFunction</em>, <em>modeling_layer: allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder</em>, <em>span_end_encoder: allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder</em>, <em>dropout: float = 0.2</em>, <em>mask_lstms: bool = True</em>, <em>initializer: allennlp.nn.initializers.InitializerApplicator = &lt;allennlp.nn.initializers.InitializerApplicator object&gt;</em>, <em>regularizer: typing.Union[allennlp.nn.regularizers.regularizer_applicator.RegularizerApplicator</em>, <em>NoneType] = None</em><span class="sig-paren">)</span> &#x2192; None<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/models/reading_comprehension/bidaf.py#L21-L354"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.reading_comprehension.bidaf.BidirectionalAttentionFlow" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="allennlp.models.model.html#allennlp.models.model.Model" title="allennlp.models.model.Model"><code class="xref py py-class docutils literal"><span class="pre">allennlp.models.model.Model</span></code></a></p>
<p>This class implements Minjoon Seo&#8217;s <a class="reference external" href="https://www.semanticscholar.org/paper/Bidirectional-Attention-Flow-for-Machine-Seo-Kembhavi/7586b7cca1deba124af80609327395e613a20e9d">Bidirectional Attention Flow model</a>
for answering reading comprehension questions (ICLR 2017).</p>
<p>The basic layout is pretty simple: encode words as a combination of word embeddings and a
character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of
attentions to put question information into the passage word representations (this is the only
part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and
do a softmax over span start and span end.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>vocab</strong> : <code class="docutils literal"><span class="pre">Vocabulary</span></code></p>
<p><strong>text_field_embedder</strong> : <code class="docutils literal"><span class="pre">TextFieldEmbedder</span></code></p>
<blockquote>
<div><p>Used to embed the <code class="docutils literal"><span class="pre">question</span></code> and <code class="docutils literal"><span class="pre">passage</span></code> <code class="docutils literal"><span class="pre">TextFields</span></code> we get as input to the model.</p>
</div></blockquote>
<p><strong>num_highway_layers</strong> : <code class="docutils literal"><span class="pre">int</span></code></p>
<blockquote>
<div><p>The number of highway layers to use in between embedding the input and passing it through
the phrase layer.</p>
</div></blockquote>
<p><strong>phrase_layer</strong> : <code class="docutils literal"><span class="pre">Seq2SeqEncoder</span></code></p>
<blockquote>
<div><p>The encoder (with its own internal stacking) that we will use in between embedding tokens
and doing the bidirectional attention.</p>
</div></blockquote>
<p><strong>attention_similarity_function</strong> : <code class="docutils literal"><span class="pre">SimilarityFunction</span></code></p>
<blockquote>
<div><p>The similarity function that we will use when comparing encoded passage and question
representations.</p>
</div></blockquote>
<p><strong>modeling_layer</strong> : <code class="docutils literal"><span class="pre">Seq2SeqEncoder</span></code></p>
<blockquote>
<div><p>The encoder (with its own internal stacking) that we will use in between the bidirectional
attention and predicting span start and end.</p>
</div></blockquote>
<p><strong>span_end_encoder</strong> : <code class="docutils literal"><span class="pre">Seq2SeqEncoder</span></code></p>
<blockquote>
<div><p>The encoder that we will use to incorporate span start predictions into the passage state
before predicting span end.</p>
</div></blockquote>
<p><strong>dropout</strong> : <code class="docutils literal"><span class="pre">float</span></code>, optional (default=0.2)</p>
<blockquote>
<div><p>If greater than 0, we will apply dropout with this probability after all encoders (pytorch
LSTMs do not apply dropout to their last layer).</p>
</div></blockquote>
<p><strong>mask_lstms</strong> : <code class="docutils literal"><span class="pre">bool</span></code>, optional (default=True)</p>
<blockquote>
<div><p>If <code class="docutils literal"><span class="pre">False</span></code>, we will skip passing the mask to the LSTM layers.  This gives a ~2x speedup,
with only a slight performance decrease, if any.  We haven&#8217;t experimented much with this
yet, but have confirmed that we still get very similar performance with much faster
training times.  We still use the mask for all softmaxes, but avoid the shuffling that&#8217;s
required when using masking with pytorch LSTMs.</p>
</div></blockquote>
<p><strong>initializer</strong> : <code class="docutils literal"><span class="pre">InitializerApplicator</span></code>, optional (default=``InitializerApplicator()``)</p>
<blockquote>
<div><p>Used to initialize the model parameters.</p>
</div></blockquote>
<p><strong>regularizer</strong> : <code class="docutils literal"><span class="pre">RegularizerApplicator</span></code>, optional (default=``None``)</p>
<blockquote class="last">
<div><p>If provided, will be used to calculate the regularization penalty during training.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="allennlp.models.reading_comprehension.bidaf.BidirectionalAttentionFlow.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>question: typing.Dict[str, torch.LongTensor], passage: typing.Dict[str, torch.LongTensor], span_start: torch.IntTensor = None, span_end: torch.IntTensor = None, metadata: typing.List[typing.Dict[str, typing.Any]] = None</em><span class="sig-paren">)</span> &#x2192; typing.Dict[str, torch.FloatTensor]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/models/reading_comprehension/bidaf.py#L131-L288"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.reading_comprehension.bidaf.BidirectionalAttentionFlow.forward" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>question</strong> : Dict[str, torch.LongTensor]</p>
<blockquote>
<div><p>From a <code class="docutils literal"><span class="pre">TextField</span></code>.</p>
</div></blockquote>
<p><strong>passage</strong> : Dict[str, torch.LongTensor]</p>
<blockquote>
<div><p>From a <code class="docutils literal"><span class="pre">TextField</span></code>.  The model assumes that this passage contains the answer to the
question, and predicts the beginning and ending positions of the answer within the
passage.</p>
</div></blockquote>
<p><strong>span_start</strong> : <code class="docutils literal"><span class="pre">torch.IntTensor</span></code>, optional</p>
<blockquote>
<div><p>From an <code class="docutils literal"><span class="pre">IndexField</span></code>.  This is one of the things we are trying to predict - the
beginning position of the answer with the passage.  This is an <cite>inclusive</cite> index.  If
this is given, we will compute a loss that gets included in the output dictionary.</p>
</div></blockquote>
<p><strong>span_end</strong> : <code class="docutils literal"><span class="pre">torch.IntTensor</span></code>, optional</p>
<blockquote>
<div><p>From an <code class="docutils literal"><span class="pre">IndexField</span></code>.  This is one of the things we are trying to predict - the
ending position of the answer with the passage.  This is an <cite>inclusive</cite> index.  If
this is given, we will compute a loss that gets included in the output dictionary.</p>
</div></blockquote>
<p><strong>metadata</strong> : <code class="docutils literal"><span class="pre">List[Dict[str,</span> <span class="pre">Any]]</span></code>, optional</p>
<blockquote>
<div><p>If present, this should contain the question ID, original passage text, and token
offsets into the passage for each instance in the batch.  We use this for computing
official metrics using the official SQuAD evaluation script.  The length of this list
should be the batch size, and each dictionary should have the keys <code class="docutils literal"><span class="pre">id</span></code>,
<code class="docutils literal"><span class="pre">original_passage</span></code>, and <code class="docutils literal"><span class="pre">token_offsets</span></code>.  If you only want the best span string and
don&#8217;t care about official metrics, you can omit the <code class="docutils literal"><span class="pre">id</span></code> key.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">An output dictionary consisting of:</p>
<p><strong>span_start_logits</strong> : torch.FloatTensor</p>
<blockquote>
<div><p>A tensor of shape <code class="docutils literal"><span class="pre">(batch_size,</span> <span class="pre">passage_length)</span></code> representing unnormalised log
probabilities of the span start position.</p>
</div></blockquote>
<p><strong>span_start_probs</strong> : torch.FloatTensor</p>
<blockquote>
<div><p>The result of <code class="docutils literal"><span class="pre">softmax(span_start_logits)</span></code>.</p>
</div></blockquote>
<p><strong>span_end_logits</strong> : torch.FloatTensor</p>
<blockquote>
<div><p>A tensor of shape <code class="docutils literal"><span class="pre">(batch_size,</span> <span class="pre">passage_length)</span></code> representing unnormalised log
probabilities of the span end position (inclusive).</p>
</div></blockquote>
<p><strong>span_end_probs</strong> : torch.FloatTensor</p>
<blockquote>
<div><p>The result of <code class="docutils literal"><span class="pre">softmax(span_end_logits)</span></code>.</p>
</div></blockquote>
<p><strong>best_span</strong> : torch.IntTensor</p>
<blockquote>
<div><p>The result of a constrained inference over <code class="docutils literal"><span class="pre">span_start_logits</span></code> and
<code class="docutils literal"><span class="pre">span_end_logits</span></code> to find the most probable span.  Shape is <code class="docutils literal"><span class="pre">(batch_size,</span> <span class="pre">2)</span></code>.</p>
</div></blockquote>
<p><strong>loss</strong> : torch.FloatTensor, optional</p>
<blockquote>
<div><p>A scalar loss to be optimised.</p>
</div></blockquote>
<p><strong>best_span_str</strong> : List[str]</p>
<blockquote class="last">
<div><p>If sufficient metadata was provided for the instances in the batch, we also return the
string from the original passage that the model thinks is the best answer to the
question.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="classmethod">
<dt id="allennlp.models.reading_comprehension.bidaf.BidirectionalAttentionFlow.from_params">
<em class="property">classmethod </em><code class="descname">from_params</code><span class="sig-paren">(</span><em>vocab: allennlp.data.vocabulary.Vocabulary</em>, <em>params: allennlp.common.params.Params</em><span class="sig-paren">)</span> &#x2192; allennlp.models.reading_comprehension.bidaf.BidirectionalAttentionFlow<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/models/reading_comprehension/bidaf.py#L328-L354"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.reading_comprehension.bidaf.BidirectionalAttentionFlow.from_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="allennlp.models.reading_comprehension.bidaf.BidirectionalAttentionFlow.get_metrics">
<code class="descname">get_metrics</code><span class="sig-paren">(</span><em>reset: bool = False</em><span class="sig-paren">)</span> &#x2192; typing.Dict[str, float]<a class="reference external" href="http://github.com/allenai/allennlp/blob/master/allennlp/models/reading_comprehension/bidaf.py#L290-L298"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#allennlp.models.reading_comprehension.bidaf.BidirectionalAttentionFlow.get_metrics" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="allennlp.models.coreference_resolution.html" class="btn btn-neutral float-right" title="allennlp.models.coreference_resolution" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="allennlp.models.encoder_decoders.html" class="btn btn-neutral" title="allennlp.models.encoder_decoders" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Allen Institute for Artificial Intelligence.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.2.2',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>